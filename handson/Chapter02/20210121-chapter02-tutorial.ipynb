{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    div#notebook-container    { width: 100%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 環境構築\n",
    "\n",
    "### Chapter 2.3.2\n",
    "\n",
    "Google Colaboratoryを使用\n",
    "<a href=\"https://colab.research.google.com/github/JapanExchangeGroup/J-Quants-Tutorial/blob/main/handson/Chapter02/20210121-chapter02-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "### Chapter 2.3.3\n",
    "\n",
    "以下の手順で環境構築して、dockerで起動したjupyter notebook で作業しています。\n",
    "```\n",
    "cd handson/\n",
    "\n",
    "# データ配置先のディレクトリを作成\n",
    "# handson/data_dirにデータをダウンロードしてきて配置しています。\n",
    "mkdir data_dir\n",
    "\n",
    "# dockerでjupyter notebookを起動します。(初回実行時は約2G程度コンテナイメージをダウンロードします。)\n",
    "# データ配置先のディレクトリを /path/to としてマウントしています。\n",
    "# 学習済みモデル提出用のディレクトリ (handson/Chapter02/archive) を /opt/ml としてマウントしています。\n",
    "# jupyter notebook作業用に handson ディレクトリを /notebook としてマウントしています。\n",
    "# jupyter notebook は port 8888でtokenとpasswordを空にして、vscode のjupyter pluginからアクセスできるように xsrf 対策を無効化しています。\n",
    "docker run --name tutorial -v ${PWD}/data_dir:/path/to -v ${PWD}/Chapter02/archive:/opt/ml -v ${PWD}:/notebook -e PYTHONPATH=/opt/ml/src -p8888:8888 --rm -it continuumio/anaconda3:2019.03 jupyter notebook --ip 0.0.0.0 --allow-root --no-browser --no-mathjax --NotebookApp.disable_check_xsrf=True  --NotebookApp.token='' --NotebookApp.password='' /notebook\n",
    "\n",
    "# ブラウザで以下のURLにアクセスしてjupyter notebookの画面が表示されていて、本チュートリアル用のnotebookが表示されていることを確認します。\n",
    "http://localhost:8888/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shap用にg++とgccをインストールします\n",
    "! apt-get update\n",
    "! apt-get install -y --no-install-recommends g++ gcc\n",
    "\n",
    "# 必要なライブラリをインストールします\n",
    "! pip install shap==0.37.0 slicer==0.0.3 xgboost==1.3.0.post0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Load Data\n",
    "\n",
    "作業に必要なライブラリをインポートして、\n",
    "以下のデータを読み込みます。\n",
    "\n",
    "- stock_price     : 株価情報\n",
    "- stock_list      : 銘柄情報 \n",
    "- stock_fin       : 財務諸表\n",
    "- stock_labels    : 目的変数\n",
    "\n",
    "本チュートリアルでは `stock_fin` および `stock_price` を使用するため、 `stock_fin_price` は読み込まずに進めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D29gV--O6c8z"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krbLDQkOaP8O"
   },
   "outputs": [],
   "source": [
    "# 表示用の設定を変更します\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.width = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHpater 2.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.7.3であることを確認します (Colab環境では3.6.9となります)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット保存先ディレクトリ\n",
    "if 'google.colab' in sys.modules:\n",
    "    dataset_dir=\"/content/drive/MyDrive/JPX_competition\"\n",
    "else:\n",
    "    dataset_dir=\"/path/to\"\n",
    "\n",
    "# 読み込むファイルを定義します。\n",
    "inputs = {\n",
    "    \"stock_list\": f\"{dataset_dir}/stock_list.csv.gz\",\n",
    "    \"stock_price\": f\"{dataset_dir}/stock_price.csv.gz\",\n",
    "    \"stock_fin\": f\"{dataset_dir}/stock_fin.csv.gz\",\n",
    "    # \"stock_fin_price\": f\"{dataset_dir}/stock_fin_price.csv.gz\",\n",
    "    \"stock_labels\": f\"{dataset_dir}/stock_labels.csv.gz\",\n",
    "}\n",
    "\n",
    "# ファイルを読み込みます\n",
    "dfs = {}\n",
    "for k, v in inputs.items():\n",
    "    print(k)\n",
    "    dfs[k] = pd.read_csv(v)\n",
    "    # DataFrameのindexを設定します。\n",
    "    if k == \"stock_price\":\n",
    "        dfs[k].loc[:, \"datetime\"] = pd.to_datetime(\n",
    "            dfs[k].loc[:, \"EndOfDayQuote Date\"]\n",
    "        )\n",
    "        dfs[k].set_index(\"datetime\", inplace=True)\n",
    "    elif k in [\"stock_fin\", \"stock_fin_price\", \"stock_labels\"]:\n",
    "        dfs[k].loc[:, \"datetime\"] = pd.to_datetime(\n",
    "            dfs[k].loc[:, \"base_date\"]\n",
    "        )\n",
    "        dfs[k].set_index(\"datetime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてアンコメントしてください。\n",
    "\n",
    "# # Timestamp型に変換する列を定義します。\n",
    "# # ファイル名: {列名: 日付文字列フォーマット}\n",
    "# datetime_mapping = {\n",
    "#     \"stock_list\": {\n",
    "#         \"Effective Date\": \"%Y%m%d\",\n",
    "#         \"IssuedShareEquityQuote ModifyDate\": \"%Y/%m/%d\"\n",
    "#     },\n",
    "#     \"stock_price\": {\n",
    "#         \"EndOfDayQuote Date\": \"%Y/%m/%d\",\n",
    "#         \"EndOfDayQuote PreviousCloseDate\": \"%Y/%m/%d\",\n",
    "#         \"EndOfDayQuote PreviousExchangeOfficialCloseDate\": \"%Y/%m/%d\",\n",
    "#     },\n",
    "#     \"stock_fin\": {\n",
    "#         \"base_date\": \"%Y/%m/%d\",\n",
    "#         \"Result_FinancialStatement ModifyDate\": \"%Y/%m/%d\",\n",
    "#         \"Forecast_FinancialStatement ModifyDate\": \"%Y/%m/%d\",\n",
    "#         \"Result_Dividend ModifyDate\": \"%Y/%m/%d\",\n",
    "#         \"Forecast_Dividend ModifyDate\": \"%Y/%m/%d\",\n",
    "#     },\n",
    "#     \"stock_labels\": {\n",
    "#         \"base_date\": \"%Y-%m-%d\",\n",
    "#         # \"label_date_5\": \"%Y-%m-%d\",\n",
    "#         \"label_date_10\": \"%Y-%m-%d\",\n",
    "#         \"label_date_20\": \"%Y-%m-%d\",\n",
    "#     }\n",
    "# }\n",
    "# # 読み込んだデータの日付列をpd.Timestamp型に変更します\n",
    "# for k, datetime_cols in datetime_mapping.items():\n",
    "#     for col, format in datetime_cols.items():\n",
    "#         dfs[k][col] = pd.to_datetime(dfs[k][col], format=format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in inputs.keys():\n",
    "    print(k)\n",
    "    print(dfs[k].info())\n",
    "    print(dfs[k].head(1).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.2.1の表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[\"stock_list\"].shape)\n",
    "dfs[\"stock_list\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.2.2の表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[\"stock_price\"].shape)\n",
    "dfs[\"stock_price\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.2.3の表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[\"stock_fin\"].shape)\n",
    "dfs[\"stock_fin\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.2.4の表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてアンコメントしてください\n",
    "\n",
    "# print(dfs[\"stock_fin_price\"].shape)\n",
    "# dfs[\"stock_fin_price\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.2.5の表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[\"stock_labels\"].shape)\n",
    "dfs[\"stock_labels\"].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.1 売上高、営業利益、純利益、純資産及びその決算期の間の関係について可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stock_finの読み込み\n",
    "fin = dfs[\"stock_fin\"]\n",
    "\n",
    "# 銘柄コード9984にデータを絞る\n",
    "code = 9984\n",
    "fin_data = fin[fin[\"Local Code\"] == code]\n",
    "\n",
    "# 2019年までの値を表示\n",
    "fin_data = fin_data[:\"2019\"]\n",
    "\n",
    "# プロット対象を定義\n",
    "columns = [\n",
    "    \"Result_FinancialStatement NetSales\",  # 売上高\n",
    "    \"Result_FinancialStatement OperatingIncome\",  # 営業利益\n",
    "    \"Result_FinancialStatement NetIncome\",  # 純利益\n",
    "    \"Result_FinancialStatement NetAssets\",  # 純資産\n",
    "    \"Result_FinancialStatement ReportType\"  # 決算期\n",
    "]\n",
    "\n",
    "# プロット\n",
    "sns.pairplot(fin_data[columns], hue=\"Result_FinancialStatement ReportType\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.1 複数銘柄のファンダメンタル情報の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stock_finの読み込み\n",
    "fin = dfs[\"stock_fin\"]\n",
    "\n",
    "# 銘柄コード9984と9983を比較する\n",
    "codes = [9984, 9983]\n",
    "\n",
    "multi_df = dict()\n",
    "\n",
    "# プロット対象を定義\n",
    "columns = [\n",
    "    \"Result_FinancialStatement NetSales\",  # 売上高\n",
    "    \"Result_FinancialStatement OperatingIncome\",  # 営業利益\n",
    "    \"Result_FinancialStatement NetIncome\",  # 純利益\n",
    "    \"Result_FinancialStatement NetAssets\",  # 純資産\n",
    "    \"Result_FinancialStatement ReportType\"  # 決算期\n",
    "]\n",
    "\n",
    "# 比較対象の銘柄コード毎に処理\n",
    "for code in codes:\n",
    "    # 特定の銘柄コードに絞り込み\n",
    "    fin_data = fin[fin[\"Local Code\"] == code]\n",
    "    # 2019年までの値を表示\n",
    "    fin_data = fin_data[:\"2019\"].copy()\n",
    "    # 重複を排除\n",
    "    fin_data.drop_duplicates(\n",
    "        subset=[\n",
    "            \"Local Code\",\n",
    "            \"Result_FinancialStatement FiscalYear\",\n",
    "            \"Result_FinancialStatement ReportType\"\n",
    "        ],\n",
    "        keep=\"last\", inplace=True)\n",
    "    # プロット対象のカラムを取得\n",
    "    _fin_data = fin_data[columns]\n",
    "    # 決算期毎の平均を取得\n",
    "    multi_df[code] = _fin_data[columns].groupby(\"Result_FinancialStatement ReportType\").mean()\n",
    "\n",
    "# 銘柄毎に処理していたものを結合\n",
    "multi_df = pd.concat(multi_df)\n",
    "# 凡例を調整\n",
    "multi_df.set_index(multi_df.index.map(lambda t: f\"{t[0]}/{t[1]}\"), inplace=True)\n",
    "# プロット\n",
    "ax = multi_df.T.plot(kind=\"bar\", figsize=(12, 6), grid=True)\n",
    "# Y軸のラベルを調整\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: \"{} bYen\".format(int(x / 1_000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.2 株価の終値の動き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceの読み込み\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 特定の銘柄コードに絞り込み\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "# 2019年までの値を表示\n",
    "price_data = price_data[:\"2019\"]\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "ax.plot(price_data[\"EndOfDayQuote ExchangeOfficialClose\"], label=f\"securities code : {code}.T\")\n",
    "ax.set_ylabel(\"stock_price\")\n",
    "ax.set_xlabel(\"datetime\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.3 移動平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceの読み込み\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 特定の銘柄コードに絞り込み\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "# 2019年までの値を表示\n",
    "price_data = price_data[:\"2019\"].copy()\n",
    "\n",
    "# 5日、25日、75日の移動平均を算出\n",
    "periods = [5, 25, 75]\n",
    "cols = []\n",
    "for period in periods:\n",
    "    col = \"{} windows simple moving average\".format(period)\n",
    "    price_data[col] = price_data[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(period, min_periods=1).mean()\n",
    "    cols.append(col)\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for col in cols:\n",
    "    ax.plot(price_data[col], label=col)\n",
    "ax.set_ylabel(\"stock_price\")\n",
    "ax.set_xlabel(\"datetime\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.4 価格変化率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceの読み込み\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 特定の銘柄コードに絞り込み\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "# 2019年までの値を表示\n",
    "price_data = price_data[:\"2019\"].copy()\n",
    "\n",
    "# 5日、25日、75日の価格変化率を算出\n",
    "periods = [5, 25, 75]\n",
    "cols = []\n",
    "for period in periods:\n",
    "    col = \"{} windows rate of return\".format(period)\n",
    "    price_data[col] = price_data[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(period) * 100\n",
    "    cols.append(col)\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for col in cols:\n",
    "    ax.plot(price_data[col], label=col)\n",
    "ax.set_ylabel(\"rate of return (%)\")\n",
    "ax.set_xlabel(\"datetime\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.5 ヒストリカル・ボラティリティ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceの読み込み\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 特定の銘柄コードに絞り込み\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "# 2019年までの値を表示\n",
    "price_data = price_data[:\"2019\"].copy()\n",
    "\n",
    "# 5日、25日、75日のヒストリカル・ボラティリティを算出\n",
    "periods = [5, 25, 75]\n",
    "cols = []\n",
    "for period in periods:\n",
    "    col = \"{} windows volatility\".format(period)\n",
    "    price_data[col] = np.log(price_data[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(period).std()\n",
    "    cols.append(col)\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "for col in cols:\n",
    "    ax.plot(price_data[col], label=col)\n",
    "ax.set_ylabel(\"volatility\")\n",
    "ax.set_xlabel(\"datetime\")\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.5.6 複数のデータを同時にプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceの読み込み\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 特定の銘柄コードに絞り込み\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "# 2019年までの値を表示\n",
    "price_data = price_data[:\"2019\"].copy()\n",
    "\n",
    "# 5日、25日、75日を対象に値を算出\n",
    "periods = [5, 25, 75]\n",
    "ma_cols = []\n",
    "# 移動平均線\n",
    "for period in periods:\n",
    "    col = \"{} windows simple moving average\".format(period)\n",
    "    price_data[col] = price_data[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(period, min_periods=1).mean()\n",
    "    ma_cols.append(col)\n",
    "\n",
    "return_cols = []\n",
    "# 価格変化率\n",
    "for period in periods:\n",
    "    col = \"{} windows rate of return\".format(period)\n",
    "    price_data[col] = price_data[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(period) * 100\n",
    "    return_cols.append(col)\n",
    "\n",
    "vol_cols = []\n",
    "# ヒストリカル・ボラティリティ\n",
    "for period in periods:\n",
    "    col = \"{} windows volatility\".format(period)\n",
    "    price_data[col] = np.log(price_data[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(period).std()\n",
    "    vol_cols.append(col)\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(nrows=3 ,figsize=(20, 8))\n",
    "\n",
    "ax[0].plot(price_data[\"EndOfDayQuote ExchangeOfficialClose\"], label=\"Close Price\")\n",
    "\n",
    "for col in ma_cols:\n",
    "    ax[0].plot(price_data[col], label=col)\n",
    "\n",
    "for col in return_cols:\n",
    "    ax[1].plot(price_data[col], label=col)\n",
    "\n",
    "for col in vol_cols:\n",
    "    ax[2].plot(price_data[col], label=col)\n",
    "\n",
    "ax[0].set_ylabel(\"stock_price\")\n",
    "ax[1].set_ylabel(\"rate of return (%)\")\n",
    "ax[2].set_ylabel(\"volatility (log return)\")\n",
    "for _ax in ax:\n",
    "    _ax.set_xlabel(\"datetime\")\n",
    "    _ax.grid(True)\n",
    "    _ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_finデータを読み込む\n",
    "stock_fin = dfs[\"stock_fin\"]\n",
    "\n",
    "# 2019年までの値を表示\n",
    "stock_fin = stock_fin[:\"2019\"]\n",
    "\n",
    "# データ数の確認\n",
    "print(stock_fin.shape)\n",
    "\n",
    "# データの欠損値数を確認\n",
    "print(stock_fin.isna().sum())\n",
    "\n",
    "# 欠損値の数を年別に集計\n",
    "stock_fin = stock_fin.isna()\n",
    "stock_fin[\"year\"] = stock_fin.index.year\n",
    "\n",
    "# データの欠損値をプロット\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "sns.heatmap(stock_fin.groupby(\"year\").agg(\"sum\"), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_finデータを読み込む\n",
    "stock_fin = dfs[\"stock_fin\"]\n",
    "\n",
    "# 銘柄コード9984にデータを絞る\n",
    "code = 9984\n",
    "stock_fin = stock_fin[stock_fin[\"Local Code\"] == code]\n",
    "\n",
    "# float64型の列に絞り込み\n",
    "fin_data = stock_fin.select_dtypes(include=[\"float64\"])\n",
    "\n",
    "# 欠損値を0でフィル\n",
    "fin_data = fin_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define features\n",
    "\n",
    "1/2/3monthのリターンに加えて標準偏差、移動平均乖離率などの特徴量生成\n",
    "\n",
    "※時刻は分析対象データを決算後翌営業日から一週間で価格データが存在していた銘柄のみにフィルタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_priceデータを読み込む\n",
    "price = dfs[\"stock_price\"]\n",
    "\n",
    "# 銘柄コード9984にデータを絞る\n",
    "code = 9984\n",
    "price_data = price[price[\"Local Code\"] == code]\n",
    "\n",
    "# 終値のみに絞る\n",
    "feats = price_data[[\"EndOfDayQuote ExchangeOfficialClose\"]].copy()\n",
    "# 終値の20営業日リターン\n",
    "feats[\"return_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(20)\n",
    "# 終値の40営業日リターン\n",
    "feats[\"return_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(40)\n",
    "# 終値の60営業日リターン\n",
    "feats[\"return_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(60)\n",
    "# 終値の20営業日ボラティリティ\n",
    "feats[\"volatility_1month\"] = (\n",
    "    np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(20).std()\n",
    ")\n",
    "# 終値の40営業日ボラティリティ\n",
    "feats[\"volatility_2month\"] = (\n",
    "    np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(40).std()\n",
    ")\n",
    "# 終値の60営業日ボラティリティ\n",
    "feats[\"volatility_3month\"] = (\n",
    "    np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(60).std()\n",
    ")\n",
    "# 終値と20営業日の単純移動平均線の乖離\n",
    "feats[\"MA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "    feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(20).mean()\n",
    ")\n",
    "# 終値と40営業日の単純移動平均線の乖離\n",
    "feats[\"MA_gap_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "    feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(40).mean()\n",
    ")\n",
    "# 終値と60営業日の単純移動平均線の乖離\n",
    "feats[\"MA_gap_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "    feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(60).mean()\n",
    ")\n",
    "# 欠損値処理\n",
    "feats = feats.fillna(0)\n",
    "# 元データのカラムを削除\n",
    "feats = feats.drop([\"EndOfDayQuote ExchangeOfficialClose\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.plot(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バックテスト期間の設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分割期間を定義\n",
    "TRAIN_END = \"2017-12-31\"\n",
    "VAL_START = \"2018-02-01\"\n",
    "VAL_END = \"2018-12-01\"\n",
    "TEST_START = \"2019-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_predict(dfs, code, start_dt=\"2015-01-01\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict)  : dict of pd.DataFrame include stock_fin, stock_price\n",
    "        code (int)  : A local code for a listed company\n",
    "        start_dt (str): specify date range\n",
    "    Returns:\n",
    "        feature DataFrame (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    # stock_finデータを読み込み\n",
    "    stock_fin = dfs[\"stock_fin\"]\n",
    "\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    fin_data = stock_fin[stock_fin[\"Local Code\"] == code]\n",
    "    # 特徴量の作成には過去60営業日のデータを使用しているため、\n",
    "    # 予測対象日からバッファ含めて土日を除く過去90日遡った時点から特徴量を生成します\n",
    "    n = 90\n",
    "    # 特徴量の生成対象期間を指定\n",
    "    fin_data = fin_data.loc[pd.Timestamp(start_dt) - pd.offsets.BDay(n) :]\n",
    "    # fin_dataのnp.float64のデータのみを取得\n",
    "    fin_data = fin_data.select_dtypes(include=[\"float64\"])\n",
    "    # 欠損値処理\n",
    "    fin_feats = fin_data.fillna(0)\n",
    "\n",
    "    # stock_priceデータを読み込む\n",
    "    price = dfs[\"stock_price\"]\n",
    "    # 特定の銘柄コードのデータに絞る\n",
    "    price_data = price[price[\"Local Code\"] == code]\n",
    "    # 終値のみに絞る\n",
    "    feats = price_data[[\"EndOfDayQuote ExchangeOfficialClose\"]]\n",
    "    # 特徴量の生成対象期間を指定\n",
    "    feats = feats.loc[pd.Timestamp(start_dt) - pd.offsets.BDay(n) :].copy()\n",
    "\n",
    "    # 終値の20営業日リターン\n",
    "    feats[\"return_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(20)\n",
    "    # 終値の40営業日リターン\n",
    "    feats[\"return_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(40)\n",
    "    # 終値の60営業日リターン\n",
    "    feats[\"return_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"].pct_change(60)\n",
    "    # 終値の20営業日ボラティリティ\n",
    "    feats[\"volatility_1month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(20).std()\n",
    "    )\n",
    "    # 終値の40営業日ボラティリティ\n",
    "    feats[\"volatility_2month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(40).std()\n",
    "    )\n",
    "    # 終値の60営業日ボラティリティ\n",
    "    feats[\"volatility_3month\"] = (\n",
    "        np.log(feats[\"EndOfDayQuote ExchangeOfficialClose\"]).diff().rolling(60).std()\n",
    "    )\n",
    "    # 終値と20営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_1month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(20).mean()\n",
    "    )\n",
    "    # 終値と40営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_2month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(40).mean()\n",
    "    )\n",
    "    # 終値と60営業日の単純移動平均線の乖離\n",
    "    feats[\"MA_gap_3month\"] = feats[\"EndOfDayQuote ExchangeOfficialClose\"] / (\n",
    "        feats[\"EndOfDayQuote ExchangeOfficialClose\"].rolling(60).mean()\n",
    "    )\n",
    "    # 欠損値処理\n",
    "    feats = feats.fillna(0)\n",
    "    # 元データのカラムを削除\n",
    "    feats = feats.drop([\"EndOfDayQuote ExchangeOfficialClose\"], axis=1)\n",
    "\n",
    "    # 財務データの特徴量とマーケットデータの特徴量のインデックスを合わせる\n",
    "    feats = feats.loc[feats.index.isin(fin_feats.index)]\n",
    "    fin_feats = fin_feats.loc[fin_feats.index.isin(feats.index)]\n",
    "\n",
    "    # データを結合\n",
    "    feats = pd.concat([feats, fin_feats], axis=1).dropna()\n",
    "\n",
    "    # 欠損値処理を行います。\n",
    "    feats = feats.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # 銘柄コードを設定\n",
    "    feats[\"code\"] = code\n",
    "\n",
    "    # 生成対象日以降の特徴量に絞る\n",
    "    feats = feats.loc[pd.Timestamp(start_dt) :]\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = get_features_for_predict(dfs, 9984)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的変数の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(dfs, codes, feature, label):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "        codes  (array) : target codes\n",
    "        feature (pd.DataFrame): features\n",
    "        label (str) : label column name\n",
    "    Returns:\n",
    "        train_X (pd.DataFrame): training data\n",
    "        train_y (pd.DataFrame): label for train_X\n",
    "        val_X (pd.DataFrame): validation data\n",
    "        val_y (pd.DataFrame): label for val_X\n",
    "        test_X (pd.DataFrame): test data\n",
    "        test_y (pd.DataFrame): label for test_X\n",
    "    \"\"\"\n",
    "    # 分割データ用の変数を定義\n",
    "    trains_X, vals_X, tests_X = [], [], []\n",
    "    trains_y, vals_y, tests_y = [], [], []\n",
    "\n",
    "    # 銘柄コード毎に特徴量を作成\n",
    "    for code in tqdm(codes):\n",
    "        # 特徴量取得\n",
    "        feats = feature[feature[\"code\"] == code]\n",
    "\n",
    "        # stock_labelデータを読み込み\n",
    "        stock_labels = dfs[\"stock_labels\"]\n",
    "        # 特定の銘柄コードのデータに絞る\n",
    "        stock_labels = stock_labels[stock_labels[\"Local Code\"] == code]\n",
    "\n",
    "        # 特定の目的変数に絞る\n",
    "        labels = stock_labels[label].copy()\n",
    "        # nanを削除\n",
    "        labels.dropna(inplace=True)\n",
    "\n",
    "        if feats.shape[0] > 0 and labels.shape[0] > 0:\n",
    "            # 特徴量と目的変数のインデックスを合わせる\n",
    "            labels = labels.loc[labels.index.isin(feats.index)]\n",
    "            feats = feats.loc[feats.index.isin(labels.index)]\n",
    "            labels.index = feats.index\n",
    "\n",
    "            # データを分割\n",
    "            _train_X = feats[: TRAIN_END]\n",
    "            _val_X = feats[VAL_START : VAL_END]\n",
    "            _test_X = feats[TEST_START :]\n",
    "\n",
    "            _train_y = labels[: TRAIN_END]\n",
    "            _val_y = labels[VAL_START : VAL_END]\n",
    "            _test_y = labels[TEST_START :]\n",
    "\n",
    "            # データを配列に格納 (後ほど結合するため)\n",
    "            trains_X.append(_train_X)\n",
    "            vals_X.append(_val_X)\n",
    "            tests_X.append(_test_X)\n",
    "\n",
    "            trains_y.append(_train_y)\n",
    "            vals_y.append(_val_y)\n",
    "            tests_y.append(_test_y)\n",
    "    # 銘柄毎に作成した説明変数データを結合します。\n",
    "    train_X = pd.concat(trains_X)\n",
    "    val_X = pd.concat(vals_X)\n",
    "    test_X = pd.concat(tests_X)\n",
    "    # 銘柄毎に作成した目的変数データを結合します。\n",
    "    train_y = pd.concat(trains_y)\n",
    "    val_y = pd.concat(vals_y)\n",
    "    test_y = pd.concat(tests_y)\n",
    "\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 対象銘柄コードを定義\n",
    "codes = [9984]\n",
    "# 対象の目的変数を定義\n",
    "label = \"label_high_20\"\n",
    "# 特徴量を取得\n",
    "feat = get_features_for_predict(dfs, codes[0])\n",
    "# 特徴量と目的変数を一致させて、データを分割\n",
    "ret = get_features_and_label(dfs, codes, feat, label)\n",
    "for v in ret:\n",
    "    print(v.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(dfs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dfs (dict[pd.DataFrame]): loaded data\n",
    "    Returns:\n",
    "        array: list of stock codes\n",
    "    \"\"\"\n",
    "    stock_list = dfs[\"stock_list\"].copy()\n",
    "    # 予測対象の銘柄コードを取得\n",
    "    codes = stock_list[stock_list[\"prediction_target\"] == True][\n",
    "        \"Local Code\"\n",
    "    ].values\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対象の目的変数を定義\n",
    "if 'google.colab' in sys.modules:\n",
    "    labels = {\n",
    "        \"label_high_20\",\n",
    "        \"label_low_20\",\n",
    "    }\n",
    "else:\n",
    "    labels = {\n",
    "        \"label_high_5\",\n",
    "        \"label_high_10\",\n",
    "        \"label_high_20\",\n",
    "        \"label_low_5\",\n",
    "        \"label_low_10\",\n",
    "        \"label_low_20\",\n",
    "    }\n",
    "\n",
    "# 目的変数毎にデータを保存するための変数\n",
    "train_X, val_X, test_X = {}, {}, {}\n",
    "train_y, val_y, test_y = {}, {}, {}\n",
    "\n",
    "# 予測対象銘柄を取得\n",
    "codes = get_codes(dfs)\n",
    "\n",
    "# 特徴量を作成\n",
    "buff = []\n",
    "for code in tqdm(codes):\n",
    "    feat = get_features_for_predict(dfs, code)\n",
    "    buff.append(feat)\n",
    "feature = pd.concat(buff)\n",
    "\n",
    "# 目的変数毎に処理\n",
    "for label in tqdm(labels):\n",
    "    # 特徴量と目的変数を取得\n",
    "    _train_X, _train_y, _val_X, _val_y, _test_X, _test_y = get_features_and_label(dfs, codes, feature, label)\n",
    "    # 目的変数をキーとして値を保存\n",
    "    train_X[label] = _train_X\n",
    "    val_X[label] = _val_X\n",
    "    test_X[label] = _test_X\n",
    "    train_y[label] = _train_y\n",
    "    val_y[label] = _val_y\n",
    "    test_y[label] = _test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を指定\n",
    "label = \"label_high_20\"\n",
    "# モデルの初期化\n",
    "pred_model = RandomForestRegressor(random_state=0)\n",
    "# モデルの学習\n",
    "pred_model.fit(train_X[label], train_y[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義\n",
    "models = {\n",
    "    \"rf\": RandomForestRegressor,\n",
    "}\n",
    "\n",
    "# モデルを選択\n",
    "model = \"rf\"\n",
    "\n",
    "# 目的変数を指定\n",
    "label = \"label_high_20\"\n",
    "\n",
    "# 特徴量グループを定義　\n",
    "# ファンダメンタル\n",
    "fundamental_cols = dfs[\"stock_fin\"].select_dtypes(\"float64\").columns\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Result_Dividend DividendPayableDate\"]\n",
    "fundamental_cols = fundamental_cols[fundamental_cols != \"Local Code\"]\n",
    "# 価格変化率\n",
    "returns_cols = [x for x in train_X[label].columns if \"return\" in x]\n",
    "# テクニカル\n",
    "technical_cols = [x for x in train_X[label].columns if (x not in fundamental_cols) and (x != \"code\")]\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "# 特徴量グループを指定\n",
    "col = \"fundamental_only\"\n",
    "\n",
    "# 学習\n",
    "pred_model = models[model](random_state=0)\n",
    "pred_model.fit(train_X[label][columns[col]].values, train_y[label])\n",
    "\n",
    "# 予測\n",
    "result = {}\n",
    "result[label] = pd.DataFrame(\n",
    "    pred_model.predict(val_X[label][columns[col]]), columns=[\"predict\"]\n",
    ")\n",
    "\n",
    "# 予測結果に日付と銘柄コードを追加\n",
    "result[label][\"datetime\"] = val_X[label][columns[col]].index\n",
    "result[label][\"code\"] = val_X[label][\"code\"].values\n",
    "\n",
    "# 予測の符号を取得\n",
    "result[label][\"predict_dir\"] = np.sign(result[label][\"predict\"])\n",
    "\n",
    "# 実際の値を追加\n",
    "result[label][\"actual\"] = val_y[label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.path.dirname(\"__file__\"), \"archive/model\")\n",
    "# tag::save_model[]\n",
    "# モデル保存先ディレクトリを作成\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "with open(os.path.join(model_path, f\"my_model_{label}.pkl\"), \"wb\") as f:\n",
    "    # モデルをpickle形式で保存\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測結果の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=result[label], x=\"predict\", y=\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[label].loc[:, [\"predict\", \"actual\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重要度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pred_model\n",
    "\n",
    "# プロット\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax.barh(fundamental_cols[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboostモデル学習　\n",
    "sample_model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(train_X[\"label_high_20\"], label=train_y[\"label_high_20\"]), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(model=sample_model, feature_perturbation='tree_path_dependent', model_output='margin')\n",
    "\n",
    "shap_values = explainer.shap_values(X=train_X[\"label_high_20\"])\n",
    "\n",
    "shap.summary_plot(shap_values, train_X[\"label_high_20\"], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, train_X[\"label_high_20\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check all the patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここで探索するモデルを定義します。\n",
    "models = {\n",
    "    \"rf\": RandomForestRegressor,\n",
    "    \"extraTree\": ExtraTreesRegressor,\n",
    "    \"gbr\": GradientBoostingRegressor,\n",
    "}\n",
    "\n",
    "all_results = dict()\n",
    "\n",
    "# ここでモデルに入れるデータセットを定義します。\n",
    "columns = {\n",
    "    \"fundamental_only\": fundamental_cols,\n",
    "    \"return_only\": returns_cols,\n",
    "    \"technical_only\": technical_cols,\n",
    "    \"fundamental+technical\": list(fundamental_cols) + list(technical_cols),\n",
    "}\n",
    "\n",
    "for model in tqdm(models.keys()):\n",
    "    all_results[model] = dict()\n",
    "    for col in tqdm(columns.keys()):\n",
    "        result = dict()\n",
    "        for label in tqdm(labels):\n",
    "            if len(test_X[label][columns[col]]) > 0:\n",
    "                pred_model = models[model](random_state=0)\n",
    "                pred_model.fit(train_X[label][columns[col]].values, train_y[label])\n",
    "                result[label] = test_X[label][[\"code\"]].copy()\n",
    "                result[label][\"datetime\"] = test_X[label][columns[col]].index\n",
    "                result[label][\"predict\"] = pred_model.predict(test_X[label][columns[col]])\n",
    "                result[label][\"predict_dir\"] = np.sign(result[label][\"predict\"])\n",
    "                result[label][\"actual\"] = test_y[label].values\n",
    "                result[label][\"actual_dir\"] = np.sign(result[label][\"actual\"])\n",
    "                result[label].dropna(inplace=True)\n",
    "\n",
    "        all_results[model][col] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in all_results.keys():\n",
    "    for col in all_results[model]:\n",
    "        tmp = pd.concat(all_results[model][col])\n",
    "        tmp[\"model\"] = model\n",
    "        tmp[\"feature\"] = col\n",
    "        results.append(tmp)\n",
    "results = pd.concat(results)\n",
    "results[\"label\"] = [x[0] for x in results.index]\n",
    "results[\"id\"] = results[\"code\"].astype(str)+results[\"datetime\"].dt.strftime('%Y%m%d')\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter2.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "\n",
    "for feature in columns:\n",
    "    matrix = dict()\n",
    "    for model in models:\n",
    "        for label in labels:\n",
    "            tmp_df = results[(results[\"model\"] == model) & (results[\"label\"] == label) & (results[\"feature\"] == feature)]\n",
    "            rmse = np.sqrt(mean_squared_error(tmp_df[\"predict\"], tmp_df[\"actual\"]))\n",
    "            accuracy = accuracy_score(tmp_df[\"predict_dir\"], tmp_df[\"actual_dir\"])\n",
    "            corr = np.corrcoef(tmp_df[\"actual\"], tmp_df[\"predict\"])[0, 1]\n",
    "            spearman_corr = spearmanr(tmp_df[\"actual\"], tmp_df[\"predict\"])[0]\n",
    "            matrix[label] = [rmse, accuracy, spearman_corr,corr, corr**2, feature, model, tmp_df.shape[0]]\n",
    "        res = pd.DataFrame.from_dict(matrix).T\n",
    "        res.columns = [\"RMSE\",\"accuracy\",\"spearman_corr\",\"corr\",\"R^2 score\",\"feature\", \"model\", \"# of samples\"]\n",
    "        all_metrics.append(res)\n",
    "all_metrics = pd.concat(all_metrics)\n",
    "all_metrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"RMSE\",\"accuracy\",\"spearman_corr\",\"corr\",\"R^2 score\"]\n",
    "for col in numeric_cols:\n",
    "    all_metrics[col] = all_metrics[col].astype(float)\n",
    "agg = all_metrics.reset_index().groupby([\"index\",\"feature\"]).agg(\"mean\")\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}