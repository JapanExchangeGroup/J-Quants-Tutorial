{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210224_chapter03_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsDycxrklAeG"
      },
      "source": [
        "%%HTML\n",
        "<style>\n",
        "    div#notebook-container    { width: 100%; }\n",
        "    div#menubar-container     { width: 65%; }\n",
        "    div#maintoolbar-container { width: 99%; }\n",
        "</style>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_84Uu72lAeR"
      },
      "source": [
        "# Google Colab環境ではGoogle Driveをマウントしてアクセスできるようにします。\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Google Drive をマウントします\n",
        "    from google.colab import drive\n",
        "    mount_dir = \"/content/drive\"\n",
        "    drive.mount(mount_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irr-l1CnlAeS"
      },
      "source": [
        "# シンプルなポートフォリオ組成モデルの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754BqhmslAeT"
      },
      "source": [
        "```\n",
        "　バックテストの実行方法を理解したので、いよいよシンプルなポートフォリオ組成モデルを作成しましょう。ポートフォリオ組成モデルを作成することを通して、本コンペティションに投稿するモデルの出力や評価方法を把握し、最終的には作成したモデルを投稿して結果がリーダーボードに掲載されることを確認します。\n",
        "\n",
        "　本節では以下を説明しています。\n",
        "\n",
        "- ポートフォリオ組成モデルの作成方法\n",
        "- バックテストの使用方法\n",
        "- 投稿用パッケージの作成方法\n",
        "\n",
        "　具体的には、以下のステップで進めていきます。\n",
        "\n",
        "[source]\n",
        "----\n",
        "1. 必要なライブラリの読み込み\n",
        "2. データセットの読み込み\n",
        "3. ポートフォリオ組成戦略の策定\n",
        "4. ポートフォリオの組成\n",
        "5. 出力の調整\n",
        "6. バックテストの実行\n",
        "7. バックテストの評価\n",
        "8. 投稿用パッケージのディレクトリ作成\n",
        "9. 作成したコードをランタイム実行用にクラスにまとめる\n",
        "10. 提出用パッケージの作成と提出\n",
        "----\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kc18w31dOrM"
      },
      "source": [
        "## 必要な入力データ等"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8PWV9pMlAeV"
      },
      "source": [
        "```\n",
        "■バックテスト用クラス +\n",
        "本コンペティションの評価方法と同等のロジックを実装したバックテスト用のクラスを提供しています。本notebookからimportできる必要があります。import時にエラーとなる場合は、`backtest.py` ファイルをダウンロードしている確認の上、sys.path に追加して再実行してください。なお、バックテスト用のクラスの取得方法は、<<anchor-3.6 ,3.6. バックテスト環境の構築>>をご参照ください。\n",
        "\n",
        "■データセット +\n",
        "本章で構築するモデルにおいては、以下のデータファイルを使用します。そのため、コンペティションサイトからダウンロードしたデータファイルを配置し、ディレクトリパスを `dataset_dir` 変数に設定してください。\n",
        "\n",
        "- stock_list.csv.gz\n",
        "- stock_price.csv.gz\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pj6dUA1lAeV"
      },
      "source": [
        "## 1. 必要なライブラリの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_lb9YzplAeV"
      },
      "source": [
        "ランタイム環境とGoogle Colaboratory環境の両者で共通のライブラリを使用するためにバージョンを調整します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En1-ETBJlAeW"
      },
      "source": [
        "# ライブラリのバージョンを調整します\n",
        "!pip install --no-cache-dir joblib==1.0.1 numpy==1.19.5 pandas==1.1.5 scikit-learn==0.20.3 scipy==1.2.1 seaborn==0.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dF8wbVClAeW"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from scipy import stats\n",
        "from IPython.core.magic import register_cell_magic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAJ6Kv5wlAeW"
      },
      "source": [
        "　次に本コンペティションの評価検証用のバックテストモジュールを読み込みます。インポート時にエラーが出た場合は、sys.path に backtest.py ファイルを配置したディレクトリを追加してから再度インポートしてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8P7FIbVlAeX"
      },
      "source": [
        "# インポート時にエラーが出た場合は、以下のmodule_dirをbacktest.pyを配置したディレクトリに変更してください。\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  # Backtestを配置したディレクトリへのフルパスを指定します\n",
        "  module_dir = f\"{mount_dir}/MyDrive/JPX_competition/Chapter03/backtest\"\n",
        "else:\n",
        "  # Backtestを配置したディレクトリへのフルパスを指定します\n",
        "  module_dir = \"/notebook/Chapter03/backtest\" \n",
        "sys.path.append(module_dir)\n",
        "\n",
        "from backtest import Backtest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVJ6SoR-lAeX"
      },
      "source": [
        "Pandasのデータを表示する際に表略されないように設定を変更します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Wj6ba1lAeX"
      },
      "source": [
        "# 表示用の設定を変更します\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.width = 120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6Ro3MFlAeX"
      },
      "source": [
        "## 2. データセットの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfIWCyvTlAeY"
      },
      "source": [
        "```\n",
        "　データセットを配置したディレクトリのパスを設定します。Google Colabをご利用の場合は Google Drive にデータセットをアップロードして、そのディレクトリを指定してください。また、データセットの取得方法および内容については「<<anchor-3.4, 3.4. データセットの説明>>」をご参照ください。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMkJK73WlAeY"
      },
      "source": [
        "# データセットを配置したディレクトリのパスを設定\n",
        "if 'google.colab' in sys.modules:\n",
        "    dataset_dir = f\"{mount_dir}/MyDrive/JPX_competition/data_dir_comp2\"\n",
        "else:\n",
        "    dataset_dir = \"/notebook/data_dir_comp2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jyty9Ms5lAeY"
      },
      "source": [
        "　本コンペティションのランタイム環境におけるデータセットへのアクセスは、 `ScoringService.predict()` メソッドに渡されるinputsパラメーターを通して行う必要があります。そのため、以下のように本notebook環境でもランタイム環境と共通の方法でデータセットにアクセスすることで、コードが複雑になったり投稿用にコードを編集したりしなくても済むようにしています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCVy3-_XlAeZ"
      },
      "source": [
        "# 入力パラメーターを設定します。ランタイム環境での実行時と同一フォーマットにします\n",
        "inputs = {\n",
        "    \"stock_list\": f\"{dataset_dir}/stock_list.csv.gz\",\n",
        "    \"stock_price\": f\"{dataset_dir}/stock_price.csv.gz\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j3pdo2zlAeZ"
      },
      "source": [
        "　本コンペティションでは2016年以降のデータを提供していますが、本notebookではモデル作成・評価時の処理時間を短くするために 2020-01-01 以降のデータを使用してバックテストを実施・評価します。なお、実際に評価をする場合は可能な限り長い期間を評価に利用することを推奨します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWL_3UDhlAeZ"
      },
      "source": [
        "# 投資対象日付を指定します\n",
        "start_dt = pd.Timestamp(\"2020-01-01\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgnrom7aMp5N"
      },
      "source": [
        "　ランタイム環境においては `ScoringService.predict()` メソッドに渡されるinputsパラメーターに `purchase_date` というキー名で予測対象日が記載されたCSV形式のファイルへのパスが渡され、そのファイル内に記載されている日付を予測対象日として使用します。ここではランタイム環境に対応するために `purchase_date` が存在する場合は、指定された日付を使用するロジックを組み込んでおきます。purchase_date のフォーマットについては link:https://signate.jp/competitions/443/data[SIGNATEのコンペティションサイト] にサンプルファイルが配置されているためそちらをご参照ください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Cb8T_vMrBQ"
      },
      "source": [
        "if \"purchase_date\" in inputs.keys():\n",
        "    # ランタイム環境では指定された投資対象日付を使用します\n",
        "    # purchase_dateを読み込み\n",
        "    df_purchase_date = pd.read_csv(inputs[\"purchase_date\"])\n",
        "    # purchase_dateの最も古い日付を投資対象日付として使用します\n",
        "    start_dt = pd.Timestamp(df_purchase_date.sort_values(\"Purchase Date\").iloc[0, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHMF4wCQlAeZ"
      },
      "source": [
        "　本コンペティションでは投資対象となる銘柄群 (ユニバース) が設定されています。そのため、ユニバース内の銘柄に絞って処理を実施するために銘柄情報を読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4G06sslAea"
      },
      "source": [
        "# 銘柄情報読み込み\n",
        "df_stock_list = pd.read_csv(inputs[\"stock_list\"])\n",
        "# 問題2のユニバース (投資対象の条件を満たす銘柄群) 取得\n",
        "codes = df_stock_list.loc[\n",
        "    df_stock_list.loc[:, \"universe_comp2\"] == True, \"Local Code\"\n",
        "].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8hXEyOlAea"
      },
      "source": [
        "　以下では、シンプルに株価情報のみを利用してポートフォリオを組成するために株価情報を読み込んでいます。本コンペティションでは、データセットはcsv.gz形式で提供していますので、データの型情報が保存されていません。そのため、特に日付型のカラムについては明示的に変換する必要があります。read_csvのparse_dateパラメーター等、日付型を指定する方法は複数ありますが、本notebookでは一度読み込んでから変換しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNLOQ18ilAea"
      },
      "source": [
        "# 価格情報読み込み、インデックス作成\n",
        "df_price = pd.read_csv(inputs[\"stock_price\"]).set_index(\"EndOfDayQuote Date\")\n",
        "# 日付型に変換\n",
        "df_price.index = pd.to_datetime(df_price.index, format=\"%Y-%m-%d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q444bBfSlAea"
      },
      "source": [
        "　処理時間を最適化するために処理対象データを日付でフィルタをして絞り込みます。本notebookでは過去20営業日のデータを使用して特徴量を作成するため、投資対象日付から過去20営業日時点のデータを含める必要がありますが、バッファとして過去30日のデータを含めることにします。同時に株価情報をユニバースと一致するように絞り込んでいます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0vaT8VlAeb"
      },
      "source": [
        "# 投資対象日の前週金曜日時点で予測を出力するため、予測出力用の日付を設定します。\n",
        "pred_start_dt = pd.Timestamp(start_dt) - pd.Timedelta(\"3D\")\n",
        "# 特徴量の生成に必要な日数をバッファとして設定\n",
        "n = 30\n",
        "# データ絞り込み日付設定\n",
        "data_start_dt = pred_start_dt - pd.offsets.BDay(n)\n",
        "# 日付で絞り込み\n",
        "filter_date = df_price.index >= data_start_dt\n",
        "# 銘柄をユニバースで絞り込み\n",
        "filter_universe = df_price.loc[:, \"Local Code\"].isin(codes)\n",
        "# 絞り込み実施\n",
        "df_price = df_price.loc[filter_date & filter_universe]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bzTSwePlAeb"
      },
      "source": [
        "　`head()` や `tail()` メソッドを使用して処理結果が期待通りとなっていることを確認しながら進めていきます。ここではデータが2019年11月20日以降に絞り込まれていることが確認できます。`.T`  プロパティ https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transpose.html#pandas.DataFrame.transpose を使用して行と列を入れ替えることで可読性が上がる場合があります。\n",
        "\n",
        "　ここで計算したデータセットのフォーマットを確認するために、データセットの先頭を見てみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIaW2QZlAeb"
      },
      "source": [
        "df_price.head(3).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gbmkmlllAeb"
      },
      "source": [
        "## 3. ポートフォリオ組成戦略の策定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ARQkPzlAec"
      },
      "source": [
        "```\n",
        "　ポートフォリオを組成するための特徴量を作成します。今回は以下の2種類の戦略を採用します。\n",
        "\n",
        "1. リターン・リバーサル (逆張り) 戦略を採用して、過去1ヶ月(約20営業日)の株価下落率の上位25銘柄を選択します。\n",
        "(「リターン・リバーサル」 野村證券証券用語解説集より引用 https://www.nomura.co.jp/terms/japan/ri/A01944.html)\n",
        "2. トレンドフォロー (順張り) 戦略を採用して、過去1ヶ月(約20営業日)の株価上昇率の上位25銘柄を選択します。\n",
        "(「トレンドフォロー」 野村證券証券用語解説集より引用 https://www.nomura.co.jp/terms/japan/ta/A02002.html)\n",
        "\n",
        "　過去1ヶ月(20営業日)の株価下落率/上昇率を計算するために、銘柄毎にグループ化してから株価変化率を計算します。 +\n",
        "　本コンペティションに提出するポートフォリオは各週の週初の営業日に買付実施されるため、買付日前週の金曜日終値時点を銘柄選択の基準とします。基準日のデータを取得するために単純に金曜日にのみ絞り込んだ場合、金曜日が祝日の場合にその翌週の銘柄を選択できなくなるおそれがあるため、平日でリサンプル(pandasにおいて平日を意味する ``B`` を指定してresample関数を呼んでいます)し、欠損値がある場合には前日の値を使うように前方補完(pandasではffill関数を利用)を実施します。これにより、金曜日に必ずデータが存在するようにしています。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mvGmuQdlAec"
      },
      "source": [
        "# 欠損値がある場合にも正しく動作しているかを確認するため、処理前に木曜日、金曜日が祝日である2020-07-23、2020-07-24のレコードが存在しないことを確認しておきます。\n",
        "df_price.loc[\"2020-07-22\":\"2020-07-27\"].head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEfoxOAlAec"
      },
      "source": [
        "# groupby を使用して処理するために並び替え\n",
        "df_price.sort_values([\"Local Code\", \"EndOfDayQuote Date\"], inplace=True)\n",
        "# 銘柄毎にグループにします。\n",
        "grouped_price = df_price.groupby(\"Local Code\")[\n",
        "    \"EndOfDayQuote ExchangeOfficialClose\"\n",
        "]\n",
        "# 銘柄毎に20営業日の変化率を作成してから、金曜日に必ずデータが存在するようにリサンプルして前方補完します。\n",
        "df_feature = grouped_price.apply(\n",
        "    lambda x: x.pct_change(20).resample(\"B\").ffill().dropna()\n",
        ").to_frame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCpPCP5UlAec"
      },
      "source": [
        "```\n",
        "　大量のデータを処理する場合、処理によっては数分から数時間かかる場合があります。処理済みのデータを保存しておくことで、処理時間のかかる処理を省略して作業できるようにすることは重要なテクニックの一つです。今回はメモリ上に別の変数として保存しておきますが、セッションが閉じられる際に処理済みデータもクリアされてしまうことに加えて、大量のデータである場合はメモリ上に保存しておくとメモリを圧迫するため、ファイルに書き出しておいて必要な時にファイルから読み込むのが良い方法です。\n",
        "\n",
        "　Pandasには様々な形式でのデータの入出力用メソッド (link:https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html[リンク]) が用意されています。例えば、データが圧縮されて型が保存される `to_hdf` メソッド (link:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_hdf.html[リンク])を使用してファイルに書き出し、対応する `read_hdf` メソッド (link:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_hdf.html[リンク])で読み出すことで簡単にデータフレームを読み書きできます。\n",
        "\n",
        "　平日を指定してデータのリサンプル行い、欠損値に前日の値を使うように前方補完した結果が期待通りになっているかを確認しましょう。2020-07-23及び2020-07-24はそれぞれ木曜日及び金曜日の祝日でしたので、2020-07-23及び2020-07-24に2020-07-22の値が入っていれば良いことになります。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifrtaXnrlAed"
      },
      "source": [
        "# 上記は比較的時間のかかる処理なので、処理済みデータを別に残しておきます。\n",
        "df_work = df_feature.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGbHFnK0lAed",
        "scrolled": true
      },
      "source": [
        "# 処理後に木曜日、金曜日が祝日である2020-07-23、2020-07-24のレコードが前方補完されていることを確認します。\n",
        "df_work.loc[(slice(None), slice(\"2020-07-22\", \"2020-07-27\")),].head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xCj6RD4dOrV"
      },
      "source": [
        "　以下のコードでデータを整えます。インデックスとカラム名を調整しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkify_45lAed"
      },
      "source": [
        "# インデックスが銘柄コードと日付になっているため、日付のみに変更します。\n",
        "df_work = df_work.reset_index(level=[0])\n",
        "# カラム名を変更します。 \n",
        "df_work.rename(\n",
        "    columns={\"EndOfDayQuote ExchangeOfficialClose\": \"pct_change\"},\n",
        "    inplace=True,\n",
        ")\n",
        "# データをpred_start_dt以降の日付に絞り込みます。\n",
        "df_work = df_work.loc[df_work.index >= pred_start_dt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49n7ghG5lAed"
      },
      "source": [
        "特徴量が生成されていることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TybKXoglAee"
      },
      "source": [
        "# df_workの最初の3行を出力する。\n",
        "df_work.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVSsPa7ylAee"
      },
      "source": [
        "## 4. ポートフォリオの組成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxvNssJPlAee"
      },
      "source": [
        "```\n",
        "　今回のポートフォリオでは買付日前週の金曜日終値時点を銘柄選択の基準とするため、金曜日のデータのみに絞り込みます。すでに「<<anchor-3.7.4,3.7.4. ポートフォリオ構築戦略の策定>>」において、金曜日が祝日の場合の処理はしていますので、そのまま金曜日に絞り込んで問題ありません。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCZZqNSKlAee"
      },
      "source": [
        "# 金曜日のデータのみに絞り込みます\n",
        "df_work = df_work.loc[df_work.index.dayofweek == 4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg8h-dMulAee"
      },
      "source": [
        "　金曜日のデータのみとなっていることを確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGVrG-O1lAee",
        "scrolled": true
      },
      "source": [
        "# df_workの最初の2行を出力する。\n",
        "df_work.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw-QQZZtlAef"
      },
      "source": [
        "```\n",
        "　次に、日付毎にグループ化してから、下落率上位25銘柄を選択しています。本コンペティションの評価では、出力されたポートフォリオに記載されている順番で銘柄が購入されるため、なるべくリターンが高くなる銘柄から先に出力して購入されるようにすることが最適と考えられます。ここでは、下落率が高い銘柄ほどリターンの大きくなるとの仮説を立てて、`pct_change` について昇順で並べ替えてから銘柄を選択しています。こうすることで下落率が高い銘柄順に出力されるようにしています。\n",
        "\n",
        "　なお、ここでは説明をシンプルにするために特に理由なく25銘柄を選択していますが、例えば、5銘柄から50銘柄まで5銘柄ずつ増加させた合計10個のポートフォリオを組成してバックテストでパフォーマンスを比較することで、この戦略における最適な選択銘柄数を見つけられるかもしれません。また、その場合、50銘柄のポートフォリオを組成しておいて、バックテスト投入時に銘柄数を絞り込むロジックを組むことで処理時間を最適化できるかもしれません。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXM6BrialAef"
      },
      "source": [
        "# 日付毎に処理するためグループ化します\n",
        "grouped_work = df_work.groupby(\"EndOfDayQuote Date\", as_index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcvcZcpXlAek"
      },
      "source": [
        "# 選択する銘柄数を指定します\n",
        "number_of_portfolio_stocks = 25\n",
        "\n",
        "# ポートフォリオの組成方法を戦略に応じて調整します\n",
        "strategies = {\n",
        "    # リターン・リバーサル戦略\n",
        "    \"reversal\": {\"asc\": True},\n",
        "    # トレンドフォロー戦略\n",
        "    \"trend\": {\"asc\": False},\n",
        "}\n",
        "\n",
        "# 戦略に応じたポートフォリオを保存します\n",
        "df_portfolios = {}\n",
        "\n",
        "# strategy_id が設定されていない場合は全ての戦略のポートフォリオを作成します\n",
        "if \"strategy_id\" not in locals():\n",
        "    strategy_id = None\n",
        "\n",
        "for i in [strategy_id] if strategy_id is not None else strategies.keys():\n",
        "    #  日付毎に戦略に応じた上位25銘柄を選択します。\n",
        "    df_portfolios[i] = grouped_work.apply(\n",
        "        lambda x: x.sort_values(\n",
        "            \"pct_change\", ascending=strategies[i][\"asc\"]\n",
        "        ).head(number_of_portfolio_stocks)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEEsRXCvlAem"
      },
      "source": [
        "```\n",
        "　以下を確認します。\n",
        "\n",
        "1. 1つの週に対して25銘柄選択されていること\n",
        "2. 戦略に応じてpct_changeの値が反転していること\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik0DsvtWlAen",
        "scrolled": false
      },
      "source": [
        "# 結果結合用\n",
        "buff = []\n",
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # ポートフォリオを表示用に保存\n",
        "    buff.append(\n",
        "        df_portfolios[i]\n",
        "        # マルチインデックスは操作しにくいので日付のみに変更します\n",
        "        .reset_index(level=[0])\n",
        "        # 先頭の26レコードを取得します\n",
        "        .head(26)\n",
        "        # 結合した後の列名をわかりやすくするために変更します\n",
        "        .rename(columns={v: f\"{i}_\" + v for v in df_portfolios[i].columns})\n",
        "    )\n",
        "# 結合して保存\n",
        "pd.concat(buff, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCo-IWfylAeo"
      },
      "source": [
        "```\n",
        "　ポートフォリオに組み入れる銘柄を決めたので、各銘柄について購入金額を指定します。今回はシンプルにするために50,000円を一律で指定して購入金額の総額を25銘柄分で合計125万とすることで、1株の価格が5万円を超えている銘柄が含まれていても予算上限に近い金額を購入できるようにしています。株価を参照して銘柄数や購入金額を調整することも検討してみてください。なお、本コンペティションのポートフォリオは、対象週の月曜日日付を指定する必要がありますので、金曜日から月曜日日付に変更しています。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SynYCYh3lAes"
      },
      "source": [
        "# 銘柄ごとの購入金額を指定\n",
        "budget = 50000\n",
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # 購入株式数を設定\n",
        "    df_portfolios[i].loc[:, \"budget\"] = budget\n",
        "    # インデックスを日付のみにします\n",
        "    df_portfolios[i].reset_index(level=[0], inplace=True)\n",
        "    # 金曜日から月曜日日付に変更\n",
        "    df_portfolios[i].index = df_portfolios[i].index + pd.Timedelta(\"3D\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf5lCeeelAes"
      },
      "source": [
        "これでポートフォリオが完成しました。完成したデータを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaslvHlllAet"
      },
      "source": [
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # 戦略名を表示\n",
        "    display(i)\n",
        "    # 表示\n",
        "    display(df_portfolios[i].head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G63ZZHmSlAet"
      },
      "source": [
        "　ポートフォリオ組成に用いた特徴量やその他のカラムが残っているため、本コンペティションで決められている出力フォーマットと一致するように出力を調整します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3fA1mYnlAeu"
      },
      "source": [
        "## 5. 出力の調整"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C38aXnU8lAeu"
      },
      "source": [
        "```\n",
        "　本コンペティションのポートフォリオの出力フォーマットは「<<anchor-3.3.4, 3.3.4. 提出するモデルの予測出力の定義>>」をご参照ください。ここでは出力フォーマットに合わせるためにインデックス名やカラム数を調整します。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v380F_XlAeu"
      },
      "source": [
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # インデックス名を設定\n",
        "    df_portfolios[i].index.name = \"date\"\n",
        "    # 出力するカラムを絞り込みます\n",
        "    df_portfolios[i] = df_portfolios[i].loc[:, [\"Local Code\", \"budget\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAg5ss07lAeu"
      },
      "source": [
        "ポートフォリオが出力フォーマットと一致していることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjBp3bKlAeu"
      },
      "source": [
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # ポートフォリオを確認\n",
        "    display(df_portfolios[i].head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsr8pSxHlAev"
      },
      "source": [
        "　本コンペティションの `ScoringService.predict` の出力仕様はcsv形式の文字列であるため、仕様に合わせて出力します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEHbTnOlAev"
      },
      "source": [
        "# 出力保存用\n",
        "outputs = {}\n",
        "# 戦略毎に処理\n",
        "for i in df_portfolios.keys():\n",
        "    # 出力します\n",
        "    out = io.StringIO()\n",
        "    # CSV形式で出力\n",
        "    df_portfolios[i].to_csv(out, header=True)\n",
        "    # 出力を保存\n",
        "    outputs[i] = out.getvalue()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjNZQnlnlAev"
      },
      "source": [
        "出力を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMV--V5glAev"
      },
      "source": [
        "# 戦略毎に処理\n",
        "for i in outputs.keys():\n",
        "    # 戦略名を表示\n",
        "    print(f'// \"{i}\"')\n",
        "    # 出力を確認\n",
        "    print(\"\\n\".join(outputs[i].split(\"\\n\")[:4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKLk2sKdlAev"
      },
      "source": [
        "バックテスト用に出力を保存しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA88kUUwlAev"
      },
      "source": [
        "# 戦略毎に処理\n",
        "for i in outputs.keys():\n",
        "    # 出力を保存します。\n",
        "    with open(f\"chapter03-tutorial-01-{i}.csv\", mode=\"w\") as f:\n",
        "        # ポートフォリオをファイルに書き出し\n",
        "        f.write(outputs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccMt7NqUlAew"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjZ2s7U-lAew"
      },
      "source": [
        "## 6. バックテストの実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmO3Ju8YlAew"
      },
      "source": [
        "```\n",
        "　本コンペティションの Public LB および Private LB と同等の評価ロジックを実装したバックテスト用の `backtest.py` ファイルを使用して、作成したポートフォリオを評価します。\n",
        "バックテストの使用法などの詳細は、「<<anchor-3.6, 3.6. バックテスト環境の構築>>」をご参照ください。\n",
        "\n",
        "　初めにバックテストを使用する際に必要なデータを準備します。バックテストの実行には以下の3つのデータが必要になります。\n",
        "\n",
        "1. ユニバース (stock_list.csv.gz)\n",
        "2. 株価 (stock_price.csv.gz)\n",
        "3. テスト対象のポートフォリオ\n",
        "\n",
        "　`Backtest.prepare_data` に1および2のデータを保存しているディレクトリへのパスを指定して、必要なデータをロードします。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ6YnFKJlAew"
      },
      "source": [
        "# データを保存しているディレクトリを指定します。\n",
        "backtest_dataset_dir = dataset_dir\n",
        "# バックテストに必要なデータを読み込みます。\n",
        "backtest_codes, backtest_price = Backtest.prepare_data(backtest_dataset_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkEZjlmlAew"
      },
      "source": [
        "　バックテスト対象の戦略であるリターン・リバーサル戦略とトレンドフォロー戦略を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSz4lSaqlAex"
      },
      "source": [
        "# ポートフォリオの組成方法\n",
        "backtest_strategies = {\n",
        "    # リターン・リバーサル戦略\n",
        "    \"reversal\": {},\n",
        "    # トレンドフォロー戦略\n",
        "    \"trend\": {},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU9aQ8OnlAex"
      },
      "source": [
        "```\n",
        "　`Backtest.load_submit` にテスト対象のポートフォリオを保存したファイルへのパスを指定して読み込みます。`load_submit` ではデータを読み込み時にフォーマットのチェックをしたり、レコード順を付与するなどのバックテスト実行のための前処理を実施しています。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4O9jophlAex"
      },
      "source": [
        "# ポートフォリオデータ保存用\n",
        "df_submits = {}\n",
        "# 先ほど出力したポートフィリオデータを読み込みます\n",
        "for i in backtest_strategies.keys():\n",
        "    # ポートフォリオを読み込み\n",
        "    df_submits[i] = Backtest.load_submit(f\"chapter03-tutorial-01-{i}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKDMIoLlAex"
      },
      "source": [
        "3つのデータを指定してバックテストを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxUmMisolAex",
        "scrolled": false
      },
      "source": [
        "# バックテスト結果リターン情報保存用\n",
        "results = {}\n",
        "# バックテスト結果銘柄情報保存用\n",
        "stocks = {}\n",
        "# 戦略毎に処理\n",
        "for i in tqdm(backtest_strategies.keys()):\n",
        "    # バックテストを実行します\n",
        "    results[i], stocks[i] = Backtest.run(df_submits[i], backtest_codes, backtest_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfC3pl3nlAex"
      },
      "source": [
        "返り値を確認します。評価は下記で実施します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzGqMp0klAey",
        "scrolled": false
      },
      "source": [
        "# バックテスト結果のサマリー\n",
        "results[\"reversal\"].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9v9FaaQlAey"
      },
      "source": [
        "# 銘柄毎の情報\n",
        "stocks[\"reversal\"].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtqubtlMlAey"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHu1VPvlAey"
      },
      "source": [
        "## 7. バックテストの評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHsBeLUXlAey"
      },
      "source": [
        "```\n",
        "　バックテストを実行して取得した、週毎のリターン情報と各銘柄毎の購入結果数の情報を評価していきます。各評価項目の定義については、「<<anchor-3.6.4, 3.6.4. バックテストの評価軸と取引戦略>>」をご参照ください。\n",
        "\n",
        "　結果の評価として以下を実施します。\n",
        "\n",
        "*週毎のリターンデータ*\n",
        "\n",
        "1. 週毎の運用実績（PL）の分布をプロット (週毎の運用実績の合計値が本コンペティションの評価項目)\n",
        "2. 週毎の運用実績の統計量の算出\n",
        "3. 週毎の勝率・ペイオフレシオ・シャープレシオの算出\n",
        "4. 週毎のリターン推移のプロット\n",
        "5. 曜日別分析のためのバイオリンプロット\n",
        "6. 週毎のリターンの累積プロット\n",
        "7. ユニバースとの散布図\n",
        "8. ユニバースに対するベータを計算\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci20xqLfdOre"
      },
      "source": [
        "### 1. 週毎の運用実績（PL）の分布をプロット (週毎の運用実績の合計値が本コンペティションの評価項目)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSD0ISD6lAez"
      },
      "source": [
        "　まず、週毎の運用実績の分布をプロットしてみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qCke4OQlAez"
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, axes = plt.subplots(1, len(results), figsize=(8 * len(results), 8), sharex=True, sharey=True)\n",
        "\n",
        "# 戦略毎に処理\n",
        "for i, k in enumerate(results.keys()):\n",
        "    # 描画位置を指定\n",
        "    ax = axes[i]\n",
        "    # 分布をプロット\n",
        "    results[k].week_pl.hist(bins=25, ax=ax)\n",
        "    # タイトルを設定\n",
        "    ax.set_title(f\"{k}: week pl distribution\")\n",
        "#　描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTldWIGlAez"
      },
      "source": [
        "　trendとreversalは共にほぼ0平均に見えますが、reversalは分布が若干広いように見え、週によっては大きなマイナスも観測されていることがわかります。おそらくCOVID-19の暴落が発生した週が該当すると想像できます。ただし、大きなプラスの週もあるため、その負けを取り返しているかもしれません。ただ、このプロットだけではあまり戦略の良し悪しはわかりません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5j_ToW_dOrf"
      },
      "source": [
        "### 2. 週毎の運用実績の統計量の算出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdzdD4YNdOrf"
      },
      "source": [
        "　週毎の運用実績の統計量を算出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4eh9bQnlAez",
        "scrolled": true
      },
      "source": [
        "# week_plの分布の統計量\n",
        "\n",
        "# 結合用データ保存\n",
        "buff = []\n",
        "# ストラテジー毎に処理\n",
        "for k in results.keys():\n",
        "    # week_plの統計量を取得します。\n",
        "    df = results[k].loc[:, [\"week_pl\"]].describe().T\n",
        "    # インデックスを編集してストラテジーのIDにする\n",
        "    df.index = [k]\n",
        "    # インデックス名変更\n",
        "    df.index.name = \"strategy_id\"\n",
        "    # 結合用に保存\n",
        "    buff.append(df)\n",
        "# 結合して表示\n",
        "pd.concat(buff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh8_aCVudOrf"
      },
      "source": [
        "　週毎の運用実績の統計量を確認すると、reversalがtrendより平均(mean)が高いことがわかります。ただし、中央値(50%)を確認するとtrendの方が高いのでreversalは小さな勝ちではなく、大きな勝ちを利用して平均を押し上げていることがわかります。また、25%分位点では大きな差異はないのに最小値はreversalがずっと小さいことから、大きな負けがあると想定されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUWy1tJpdOrf"
      },
      "source": [
        "### 3. 週毎の勝率・ペイオフレシオ・シャープレシオの算出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66BAOKqElAez"
      },
      "source": [
        "　週毎の勝率、ペイオフレシオ、シャープレシオを算出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6xVAxjYlAe0",
        "scrolled": true
      },
      "source": [
        "# 結合用データ保存\n",
        "buff = []\n",
        "# 戦略毎に処理\n",
        "for k in results.keys():\n",
        "    df_return = results[k]\n",
        "    # 計算結果保存用\n",
        "    d = {}\n",
        "    # 件数\n",
        "    d[\"count\"] = df_return.shape[0]\n",
        "    # 勝率\n",
        "    d[\"win_ratio\"] = (\n",
        "        df_return.loc[df_return.loc[:, \"week_return\"] > 0].shape[0] / d[\"count\"]\n",
        "    )\n",
        "    # ペイオフレシオ\n",
        "    d[\"payoff_ratio\"] = df_return.loc[\n",
        "        df_return.loc[:, \"week_return\"] > 0, \"week_return\"\n",
        "    ].mean() / (\n",
        "        -1 * df_return.loc[df_return.loc[:, \"week_return\"] <= 0, \"week_return\"].mean()\n",
        "    )\n",
        "    # シャープレシオ\n",
        "    d[\"sharp\"] = (\n",
        "        df_return.loc[:, \"week_return\"].mean() / df_return.loc[:, \"week_return\"].std()\n",
        "    )\n",
        "    # 平均PL\n",
        "    d[\"avgPL\"] = df_return.loc[:, \"week_pl\"].mean()\n",
        "    # week_plの合計\n",
        "    d[\"PL\"] = df_return.loc[:, \"week_pl\"].sum()\n",
        "    # strategy_idを設定\n",
        "    df = pd.DataFrame([d], index=[k])\n",
        "    # インデックス名を指定\n",
        "    df.index.name = \"strategy_id\"\n",
        "    # 結合用に保存\n",
        "    buff.append(df)\n",
        "# 結合して表示\n",
        "pd.concat(buff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s36coAwdOrg"
      },
      "source": [
        "　reversalの週毎の勝率は50%ですが、payoff_ratioも1がより大きく一回の勝ちが負けよりおおきいことがわかります。trendはを勝率が60%を超えており、reversalよりも安定的に勝てるポートフォリオの可能性があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdI0Li5qdOrg"
      },
      "source": [
        "### 4. 週毎のリターン推移のプロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mca-82ktlAe0"
      },
      "source": [
        "　週毎の1日目から5日目までのリターンの推移をプロットし、曜日毎に勝ち負けの分布に差異が無いかを確認しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi0OmapVlAe0",
        "scrolled": false
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, axes = plt.subplots(\n",
        "    len(results), 1, figsize=(20, 4 * len(results)), sharex=True, sharey=True\n",
        ")\n",
        "\n",
        "# 描画用データ保存用\n",
        "dfs_plot = {}\n",
        "\n",
        "# 戦略毎に処理\n",
        "for i, k in enumerate(results.keys()):\n",
        "    # 描画位置を指定\n",
        "    ax = axes[i]\n",
        "    # 列を行に変換\n",
        "    dfs_plot[k] = (\n",
        "        results[k]\n",
        "        .set_index(\"date\")\n",
        "        .loc[\n",
        "            :,\n",
        "            [\n",
        "                \"day_1_return\",\n",
        "                \"day_2_return\",\n",
        "                \"day_3_return\",\n",
        "                \"day_4_return\",\n",
        "                \"day_5_return\",\n",
        "            ],\n",
        "        ]\n",
        "        .stack()\n",
        "        .to_frame()\n",
        "        .reset_index()\n",
        "        .rename(columns={0: \"return\"})\n",
        "    )\n",
        "    # 作業用に変数設定\n",
        "    df_plot = dfs_plot[k]\n",
        "    # 曜日毎のreturnをプロット\n",
        "    df_plot.groupby([\"level_1\", \"date\"]).first().unstack().plot(ax=ax, legend=False)\n",
        "    # タイトルを設定\n",
        "    ax.set_title(f\"{k}: Daily returns\")\n",
        "    # リターンが0の位置に基準線を描画\n",
        "    ax.axhline(y=0, color=\"black\")\n",
        "    # グリッドを表示\n",
        "    ax.grid(True)\n",
        "# 描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-cnxyLMdOrg"
      },
      "source": [
        "### 5. 曜日別分析のためのバイオリンプロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLzaYRADlAe1"
      },
      "source": [
        "```\n",
        "　上のグラフでは何が起きているかわかりにくいので、seabornのバイオリンプロット(link:https://seaborn.pydata.org/generated/seaborn.violinplot.html[リンク])を利用します。バイオリンプロットはデータの密度分布を確認できるグラフであり、統計的な差異がありそうな箇所を発見するために便利です。バイオリンの形状はカーネル密度推定による確率密度関数を表しており、バイオリンの中心部分に平均、中央値、25%タイル、75%タイルを示す箱が表示されています。\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPpL0avalAe1",
        "scrolled": false
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, axes = plt.subplots(len(results), 1, figsize=(15, 4 * len(results)), sharex=True, sharey=True)\n",
        "\n",
        "# 戦略毎に処理\n",
        "for i, k in enumerate(results.keys()):\n",
        "    # 描画位置を指定\n",
        "    ax = axes[i]\n",
        "    # 箱が見やすいように横方向を指定してプロット\n",
        "    sns.violinplot(x=\"return\", y=\"level_1\", data=dfs_plot[k], ax=ax, orient=\"h\")\n",
        "    # タイトルを設定\n",
        "    ax.set_title(f\"{k}: daily return\")\n",
        "    # グリッドを表示\n",
        "    ax.grid(True)\n",
        "# 文字が重なって読みにくいので間隔調整\n",
        "fig.tight_layout(pad=2.0)\n",
        "# 描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmQUcQ8wdOrh"
      },
      "source": [
        "　reversal/trendは木・金曜日に負ける傾向がありそうです。trendはプラス側の裾野が若干広いように思われます。これはトレンドフォローを行うと大きな勝ちが取れている可能性が示唆されます。\n",
        "\n",
        "　取引戦略によっては月曜日に大きく勝つモデルや金曜日に大きく負けるなど曜日によって強さが異なることも多く、このような曜日ごとのプロットはその銘柄の特性を知る上で、確認する価値があります。特に曜日や月などの周期でチェックする場合、負けている方(このグラフでいうととマイナス側の分布)に注目することが重要です。周期性を狙って収益を意図的に取得することは難易度の高いテクニックですが、負けの場合は理由をしっかりと分析すると防げる可能性があるためです。例えば、よくあるのが金曜日特有の週末に発生するクローズオーダーなど、機関投資家のルールにより発生する取引です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd-YRxxwdOrh"
      },
      "source": [
        "### 6. 週毎のリターンの累積プロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX_9vecVlAe1"
      },
      "source": [
        "　次にいよいよ取得した収益率の時系列を累積プロットします。まず、比較対象として取引対象の全銘柄の平均週次リターンを計算します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DgZoggClAe1"
      },
      "source": [
        "# 変数名を調整します。\n",
        "# backtest_priceはユニバースで絞り込み済みです\n",
        "df_price = backtest_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfwgf3mGlAe1"
      },
      "source": [
        "# 週毎に始値と終値を取得\n",
        "df_wp = (\n",
        "    # start_dt以降の日付のみ計算\n",
        "    df_price.loc[df_price.index >= start_dt].sort_values([\"Local Code\", \"EndOfDayQuote Date\"])\n",
        "    # 銘柄コード毎に処理\n",
        "    .groupby(\"Local Code\")\n",
        "    # 月曜日スタートで週にリサンプル\n",
        "    .resample(\"W-MON\", label=\"left\", closed=\"left\")\n",
        "    # 始値は最初のレコード、終値は最後のレコードを取得\n",
        "    .agg({\"EndOfDayQuote Open\": \"first\", \"EndOfDayQuote ExchangeOfficialClose\": \"last\"})\n",
        "    # マルチインデックスを解除\n",
        "    .reset_index(level=[0])\n",
        ")\n",
        "# Open が 0.0 の銘柄は値段が付かなかった銘柄で、バックテストでは購入対象外であるため除外する\n",
        "df_wp = df_wp.loc[df_wp.loc[:, \"EndOfDayQuote Open\"] != 0.0]\n",
        "# 銘柄毎の週次リターンを計算\n",
        "df_wp.loc[:, \"universe\"] = (\n",
        "    (\n",
        "        (\n",
        "            df_wp.loc[:, \"EndOfDayQuote ExchangeOfficialClose\"]\n",
        "            / df_wp.loc[:, \"EndOfDayQuote Open\"]\n",
        "        )\n",
        "        - 1\n",
        "    )\n",
        "    * 100\n",
        ")\n",
        "# ユニバースの週毎のリターンを計算します。\n",
        "df_universe_return = df_wp.groupby(df_wp.index)[\"universe\"].mean().to_frame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P80rrJi9lAe2"
      },
      "source": [
        "　対比軸である取引対象の全銘柄の平均週次リターンが準備できたら、今回の取引戦略の結果と一緒にプロットしてみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3nUctqNlAe2",
        "scrolled": false
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, axes = plt.subplots(1, 1, figsize=(20, 8), sharex=True, sharey=True)\n",
        "\n",
        "# 戦略毎に処理\n",
        "for k in results.keys():\n",
        "    # 描画位置を指定\n",
        "    ax = axes\n",
        "    # 戦略別の累積リターンを描画\n",
        "    results[k].set_index(\"date\").loc[:, [\"week_return\"]].rename(\n",
        "        columns={\"week_return\": f\"{k}: week_return\"}\n",
        "    ).cumsum().plot(ax=ax)\n",
        "\n",
        "# ユニバースの週次リターンの累積をプロット\n",
        "df_universe_return.cumsum().plot(ax=ax, color=\"black\", label=\"universe\")\n",
        "\n",
        "# 表示を調整\n",
        "ax.set_title(\"Cumulative week_return\")\n",
        "# グリッドを表示\n",
        "ax.grid(True)\n",
        "# 描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiSiRR_FdOri"
      },
      "source": [
        "　このプロットは興味深いことがわかります。\n",
        "\n",
        "　まずreversalは、3月に発生した負けが非常に大きいことがわかります。ベンチマークはおよそ-20%の負けとなっているのに対し、reversalでは-40%に到達しています。これはリターン・リバーサル戦略を採用した場合、マーケット暴落時に負けが積み重なる現象として知られています。一方、その後に0%近辺まで戻しているので3月後半から5月末にかけて、取得できたリターンは非常に大きいこともわかります。ただ、対比軸である取引対象の全銘柄の平均週次リターンには到達していません。その後、reversal戦略のユニバースに対する有意性は6月以降はあまり観測できず、12月までユニバースの平均に勝てないまま最終的に負けています。\n",
        "\n",
        "　次に、trendは3月上旬の負けがユニバースの平均と比較すると小さいことがわかります。一方、reversal戦略の場合に観測された大きな収益性は観測できず、6月にユニバースの平均と同一の水準になると、以降はreversalと同等に12月までユニバースの平均に勝てないまま最終的に負けています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnCW5K0XdOri"
      },
      "source": [
        "### 7. ユニバースとの散布図"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWAVBwkrlAe2"
      },
      "source": [
        "　ユニバースとリターンの散布図は、マーケットの動きに対してポートフォリオの運用実績がどのように分布するかを確認するために利用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAbrFzmhlAe2",
        "scrolled": false
      },
      "source": [
        "# 戦略毎に処理\n",
        "for k in results.keys():\n",
        "    # 散布図をプロット\n",
        "    p = sns.jointplot(\n",
        "        x=df_universe_return.iloc[:, 0],\n",
        "        y=results[k].loc[:, \"week_return\"],\n",
        "        kind=\"reg\",\n",
        "        height=5,\n",
        "        stat_func=stats.pearsonr,\n",
        "    )\n",
        "    # タイトルを設定\n",
        "    p.fig.suptitle(f\"{k}: week_return vs universe\")\n",
        "    # タイトル表示用に位置を調整\n",
        "    p.fig.subplots_adjust(top=0.95)\n",
        "    # 描画\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr1BjG75dOri"
      },
      "source": [
        "　reversalはユニバースに対して、全体が下がった時に負けが大きく、ユニバースが上がった時に勝ちがわずかにユニバースを上回ることが観測できます。trendは分布が広がっており、ユニバースの影響をあまり受けていないことがわかります。また、0でリターンを稼いでいる週が多く観測出来、マーケットが動いていない時に細かく勝てている可能性が示唆されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK6F8l4JdOrj"
      },
      "source": [
        "### 8. ユニバースに対するベータを計算"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dDl7e63lAe2"
      },
      "source": [
        "　上記の傾向はベータを計算すると一目瞭然です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA4DBX0PlAe2"
      },
      "source": [
        "# 結合用に保存\n",
        "buff = []\n",
        "# 戦略毎に処理\n",
        "for k in results.keys():\n",
        "    # ベータを計算\n",
        "    res = stats.linregress(df_universe_return.iloc[:,0], results[k].loc[:, \"week_return\"])\n",
        "    # 一覧表示用にデータフレームを作成\n",
        "    df_beta = pd.DataFrame([res.slope], index=[k], columns=[\"beta\"])\n",
        "    # インデックス名を設定\n",
        "    df_beta.index.name = \"storategy_id\"\n",
        "    # 保存\n",
        "    buff.append(df_beta)\n",
        "# 結合して表示\n",
        "pd.concat(buff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N5VPe-8lAe3"
      },
      "source": [
        "　reversalはベータがおよそ1.6となっており、ユニバースが10%変動すると16%程度の変動が発生する取引戦略であることがわかります。ユニバースが-20%変動したときは-32%変動しますので、暴落時の大きな負けもこのベータ値の高さで説明ができます。3月のようにドローダウンが深くなる現象は、高いベータを持つ取引戦略にはよく観測されます。trendはベータが0.8近辺となっており、reversalと比較すると低いベータとなっています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFl76RUplAe3"
      },
      "source": [
        "### 銘柄毎に分析するための準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVT0vstylAe3"
      },
      "source": [
        "　最後に銘柄毎のデータを使用して分析していきます。\n",
        "\n",
        "*各銘柄毎のデータ*\n",
        "\n",
        "1. 銘柄毎の運用実績の分布をプロット\n",
        "2. 銘柄毎のreturnの分布をプロット\n",
        "3. 週毎の勝ち銘柄率をプロット、統計量の算出\n",
        "\n",
        "銘柄毎のデータを使用して分析するために必要な計算を実施します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cOlBxt1lAe3"
      },
      "source": [
        "# 分析用データ保存用\n",
        "dfs_analyze = {}\n",
        "# 戦略毎に処理\n",
        "for i in stocks.keys():\n",
        "    # 分析用にデータをコピー\n",
        "    df_analyze = stocks[i].copy()\n",
        "    # day5に必ず値が存在するように調整します\n",
        "    df_analyze.loc[:, [\"day_1\", \"day_2\", \"day_3\", \"day_4\", \"day_5\"]] = (\n",
        "        df_analyze.loc[:, [\"day_1\", \"day_2\", \"day_3\", \"day_4\", \"day_5\"]]\n",
        "        .replace(0.0, np.nan)\n",
        "        .ffill(axis=1)\n",
        "    )\n",
        "    # 終値とエントリーの差分を計算\n",
        "    df_analyze.loc[:, \"diff\"] = df_analyze.loc[:, [\"entry\", \"day_5\"]].diff(axis=1)[\n",
        "        \"day_5\"\n",
        "    ]\n",
        "    # 損益を計算します\n",
        "    df_analyze.loc[:, \"pl\"] = df_analyze.loc[:, \"diff\"] * df_analyze.loc[:, \"actual\"]\n",
        "    # リターンを計算します\n",
        "    df_analyze.loc[:, \"return\"] = (\n",
        "        (df_analyze.loc[:, \"day_5\"] / df_analyze.loc[:, \"entry\"]) - 1\n",
        "    ) * 100\n",
        "    # infを0.0に変換\n",
        "    df_analyze = df_analyze.replace(np.inf, 0.0)\n",
        "    # 処理結果を保存\n",
        "    dfs_analyze[i] = df_analyze"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D10XEOgdOrk"
      },
      "source": [
        "### 1.銘柄毎の運用実績の分布をプロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9BX4FBglAe3"
      },
      "source": [
        "分析用データを表示して確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHwbGlYdlAe3"
      },
      "source": [
        "dfs_analyze[\"reversal\"].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4lf_nMBdOrk"
      },
      "source": [
        "### 2.銘柄毎のリターンの分布をヒストグラムでプロット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqVjU8VlAe4"
      },
      "source": [
        "銘柄毎の各週のデータを確認します。銘柄毎のリターンの分布をヒストグラムでまずはプロットします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEDmgwmdlAe4",
        "scrolled": false
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, axes = plt.subplots(1, len(dfs_analyze), figsize=(8 * len(dfs_analyze), 8), sharex=True, sharey=True)\n",
        "\n",
        "# 戦略毎に処理\n",
        "for i, k in enumerate(dfs_analyze.keys()):\n",
        "    # 描画位置を指定\n",
        "    ax = axes[i]\n",
        "    # ヒストグラムをプロット\n",
        "    dfs_analyze[k].groupby([\"date\", \"Local Code\"])[\"return\"].sum().hist(bins=50, log=True, ax=ax)\n",
        "    # タイトルを設定\n",
        "    ax.set_title(f\"{k}: Weekly PL distribution\")\n",
        "# 描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWJATD8mdOrk"
      },
      "source": [
        "　銘柄毎リターンの分布をプロットしてみましたが、ここから何か知見は得ることは難しそうです。上のプロットからもこれといった知見をえることはできません。あえて言うなら、reversalが若干trendと比較すると裾野が広い程度です。ただし、リターンを大きな勝ちに依存している戦略や、負けの裾野が非常に広い戦略などもこのプロットで観測できるため、リターンの分布は常に確認することをおすすめします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHG036JtdOrl"
      },
      "source": [
        "### 3.週毎に勝ち銘柄率を算出、統計量の算出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w1xRV_dlAe4"
      },
      "source": [
        "最後に週毎の銘柄の勝率を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRCozqTPlAe4"
      },
      "source": [
        "# 描画領域を定義\n",
        "fig, ax = plt.subplots(1, 1, figsize=(20, 8), sharex=True, sharey=True)\n",
        "\n",
        "# 統計量表示用\n",
        "buff = []\n",
        "# 戦略毎に処理\n",
        "for k in dfs_analyze.keys():\n",
        "    # 週毎の勝ち銘柄率を計算\n",
        "    win_ratio = (\n",
        "        dfs_analyze[k]\n",
        "        .set_index(\"date\")\n",
        "        .groupby(\"date\")\n",
        "        .apply(lambda x: (x.pl > 0).sum() / x.shape[0])\n",
        "        .to_frame()\n",
        "        .rename(columns={0: f\"{k}: win_ratio\"})\n",
        "    )\n",
        "    # プロット\n",
        "    win_ratio.plot(ax=ax)\n",
        "    # 統計量を保存\n",
        "    buff.append(win_ratio.describe().T)\n",
        "# ユニバースの勝ち銘柄率をプロット\n",
        "df_wp.groupby(df_wp.index).apply(lambda x: (x.universe > 0).sum() / x.shape[0]).rename(\n",
        "    \"universe\"\n",
        ").to_frame().plot(ax=ax, color=\"black\")\n",
        "# タイトルを設定\n",
        "ax.set_title(\"win ratio of selected stocks\")\n",
        "# グリッド表示\n",
        "ax.grid(True)\n",
        "# 0.5に基準線を描画\n",
        "ax.axhline(y=0.5, color=\"red\")\n",
        "#  描画\n",
        "plt.show()\n",
        "# 週毎の勝ち銘柄率の統計量\n",
        "display(pd.concat(buff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5xYVecUdOrl"
      },
      "source": [
        "　このプロットは黒線のuniverseに対してどの時期に銘柄単位で勝率が低く、どの時期に勝率が高かったを確認しています。trendは暴落後にあまり収益を得ることができませんでしたが、revesalやunivereとの差異が観測できます。 +\n",
        "もし、銘柄単位の勝率で大きな差異が発生していないのに、収益に差異が出ている場合はその時の銘柄の勝ち幅が大きい可能性があります。また、9月以降にもみ合いになってしまった時期はこの勝率でも50%近辺で揉み合っており、取引戦略の優位性が発揮できていない時期であることがわかります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsUUhkaAdOrl"
      },
      "source": [
        "### 考察"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMHV4TrElAe4"
      },
      "source": [
        "　ここまででいろいろな観点からreversalとtrendの評価を実施してきました。3月末以降のリターン・リバーサル戦略が有効に働いている時期もありましたし、トレンドフォロー戦略でベータ値を低く抑える可能性があることがわかりました。\n",
        "\n",
        "　基本的にリターン・リバーサル戦略とトレンドフォロー戦略は安定して勝てる手法ではなく、リバーサル・モメンタムという代表的なファクターと密接な関係があり、マーケットの局面ごとに有効な戦略が変わっていることが知られています。ここまでの結果から、適切にリターン・リバーサル戦略とトレンドフォロー戦略をモデルで切り替えることが実現できれば、高い収益が実現できるポテンシャルがありそうです。そのような機械学習モデルの構築を検討する価値はあるでしょう。\n",
        "\n",
        "　このように様々な可視化を通して、取引戦略を評価することで、取引戦略を発展させていくことができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjP7thxclAe5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttrOU5jdlAe5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ObeNe1lAe5"
      },
      "source": [
        "## 8. 投稿用パッケージのディレクトリ作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8XT5yxTlAe5"
      },
      "source": [
        "```\n",
        "　ここまで、モデルの作成及び評価をしてきました。ここからは、投稿用のパッケージを作成します。ランタイム環境用のモデルは以下の構成である必要がありますので、まずは必要なディレクトリを作成していきます。\n",
        "\n",
        "[source]\n",
        "----\n",
        ".\n",
        "├── model                  必須 学習済モデルを置くディレクトリ\n",
        "│   └── ...\n",
        "├── src                    必須 Python のプログラムを置くディレクトリ\n",
        "│   ├── predictor.py       必須 最初にプログラムが呼び出すファイル\n",
        "│   └── ...                その他のファイル (ディレクトリも作成可能)\n",
        "└── requirements.txt       任意\n",
        "\n",
        "----\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_1EuBiclAe5"
      },
      "source": [
        "# 作業用のディレクトリを設定\n",
        "if 'google.colab' in sys.modules:\n",
        "    working_dir = \"/content/drive/MyDrive/JPX_competition/Chapter03\"\n",
        "else:\n",
        "    working_dir = \".\"\n",
        "# パッケージのrootディレクトリ\n",
        "package_dir = f\"{working_dir}/archive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzeOKZE_lAe6"
      },
      "source": [
        "# 必要なディレクトリを作成します\n",
        "os.makedirs(f\"{package_dir}/model\", exist_ok=True) \n",
        "os.makedirs(f\"{package_dir}/src\", exist_ok=True) \n",
        "# 今回はmodelディレクトリに保存するファイルがないため空ファイルを作成します\n",
        "open(f\"{package_dir}/model/dummy.txt\", mode=\"a\").close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVdXE7NelAe6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWdPmqh1lAe6"
      },
      "source": [
        "## 9. 作成したコードをランタイム実行用にクラスにまとめる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax-tXAo0lAe6"
      },
      "source": [
        "　notebookの各セルで実行する内容をファイルに書き出すために、jupyter notebookにマジックコマンドを追加します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_I6LHF7lAe6"
      },
      "source": [
        "# jupyter notebookにマジックコマンドを追加します\n",
        "# セル実行と同時にセル内の記載内容をファイルに書き込みます\n",
        "@register_cell_magic\n",
        "def writerun(line, cell):\n",
        "    # 書き込み先ファイルパスを取得\n",
        "    file_path = line.split()[-1]\n",
        "    # 親ディレクトリ名を取得\n",
        "    p_dir = os.path.dirname(file_path)\n",
        "    # 親ディレクトリが存在する場合は\n",
        "    if p_dir != \"\":\n",
        "        # ディレクトリ作成\n",
        "        os.makedirs(p_dir, exist_ok=True)\n",
        "    # cellの内容をファイルに書き込み\n",
        "    with open(file_path, mode=\"w\") as f:\n",
        "        f.write(cell)\n",
        "    # cellを実行\n",
        "    get_ipython().run_cell(cell)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSp1JLhElAe7"
      },
      "source": [
        "　以下のコードは、ここまでに一行ずつ作成したコードを投稿用の `ScoringService` としてまとめて実装したものになります。また、今回は学習済モデルのパラメーターなどをファイルに書き出していないため、`get_model` メソッドでは何もせずにTrueを返しています。そして、`predict` メソッドには上記で実行したコードをコピーして貼り付けています。表示用のコードおよび作業用データのコピーについてはランタイム環境では実行する必要がないため削除しています。\n",
        "\n",
        "　jupyter notebookのセルに `ScoringService` クラスを作成している理由は、`ScoringService` クラスの出力するポートフォリオがこれまで検証してきたポートフォリオと同一であることの検証が容易であるためです。慣れている方は直接`predictor.py` ファイル上で作業することを好まれるかもしれません。\n",
        "\n",
        "　次のセルでは、セルの先頭で `writerun` マジックコマンドを指定することで、実行時にセルの内容が `$package_dir/src/predictor.py` ファイルに書き込まれます。すでにファイルが存在している場合は上書きされるためご注意ください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCpB1yxtlAe7"
      },
      "source": [
        "%%writerun $package_dir/src/predictor.py\n",
        "# -*- coding: utf-8 -*-\n",
        "import io\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class ScoringService(object):\n",
        "    @classmethod\n",
        "    def get_model(cls, model_path=\"../model\"):\n",
        "        return True\n",
        "\n",
        "    @classmethod\n",
        "    def predict(\n",
        "        cls, inputs, start_dt=pd.Timestamp(\"2021-02-01\"), strategy_id=\"reversal\"\n",
        "    ):\n",
        "        ####\n",
        "        # データセットを読み込みます\n",
        "        ####\n",
        "        # 銘柄情報読み込み\n",
        "        df_stock_list = pd.read_csv(inputs[\"stock_list\"])\n",
        "        # 問題2のユニバース (投資対象銘柄群) 取得\n",
        "        codes = df_stock_list.loc[\n",
        "            df_stock_list.loc[:, \"universe_comp2\"] == True, \"Local Code\"\n",
        "        ].unique()\n",
        "\n",
        "        # 価格情報読み込み、インデックス作成\n",
        "        df_price = pd.read_csv(inputs[\"stock_price\"]).set_index(\"EndOfDayQuote Date\")\n",
        "        # 日付型に変換\n",
        "        df_price.index = pd.to_datetime(df_price.index, format=\"%Y-%m-%d\")\n",
        "\n",
        "        if \"purchase_date\" in inputs.keys():\n",
        "            # ランタイム環境では指定された投資対象日付を使用します\n",
        "            # purchase_dateを読み込み\n",
        "            df_purchase_date = pd.read_csv(inputs[\"purchase_date\"])\n",
        "            # purchase_dateの最も古い日付を設定\n",
        "            start_dt = pd.Timestamp(df_purchase_date.sort_values(\"Purchase Date\").iloc[0, 0])\n",
        "\n",
        "        # 投資対象日の前週金曜日時点で予測を出力するため、予測出力用の日付を設定します。\n",
        "        pred_start_dt = pd.Timestamp(start_dt) - pd.Timedelta(\"3D\")\n",
        "        # 特徴量の生成に必要な日数をバッファとして設定\n",
        "        n = 30\n",
        "        # データ絞り込み日付設定\n",
        "        data_start_dt = pred_start_dt - pd.offsets.BDay(n)\n",
        "        # 日付で絞り込み\n",
        "        filter_date = df_price.index >= data_start_dt\n",
        "        # 銘柄をユニバースで絞り込み\n",
        "        filter_universe = df_price.loc[:, \"Local Code\"].isin(codes)\n",
        "        # 絞り込み実施\n",
        "        df_price = df_price.loc[filter_date & filter_universe]\n",
        "\n",
        "        ####\n",
        "        # シンプルな特徴量を作成します\n",
        "        ####\n",
        "        # groupby を使用して処理するために並び替え\n",
        "        df_price.sort_values([\"Local Code\", \"EndOfDayQuote Date\"], inplace=True)\n",
        "        # 銘柄毎にグループにします。\n",
        "        grouped_price = df_price.groupby(\"Local Code\")[\n",
        "            \"EndOfDayQuote ExchangeOfficialClose\"\n",
        "        ]\n",
        "        # 銘柄毎に20営業日の変化率を作成してから、金曜日に必ずデータが存在するようにリサンプルしてフィルします\n",
        "        df_feature = grouped_price.apply(\n",
        "            lambda x: x.pct_change(20).resample(\"B\").ffill().dropna()\n",
        "        ).to_frame()\n",
        "\n",
        "        # 上記が比較的時間のかかる処理なので、処理済みデータを残しておきます。\n",
        "        df_work = df_feature  # copyはランタイム実行時には不要なので削除しています\n",
        "\n",
        "        # インデックスが銘柄コードと日付になっているため、日付のみに変更します。\n",
        "        df_work = df_work.reset_index(level=[0])\n",
        "        # カラム名を変更します\n",
        "        df_work.rename(\n",
        "            columns={\"EndOfDayQuote ExchangeOfficialClose\": \"pct_change\"},\n",
        "            inplace=True,\n",
        "        )\n",
        "        # データをpred_start_dt以降の日付に絞り込みます\n",
        "        df_work = df_work.loc[df_work.index >= pred_start_dt]\n",
        "\n",
        "        ####\n",
        "        # ポートフォリオを組成します\n",
        "        ####\n",
        "        # 金曜日のデータのみに絞り込みます\n",
        "        df_work = df_work.loc[df_work.index.dayofweek == 4]\n",
        "\n",
        "        # 日付毎に処理するためグループ化します\n",
        "        grouped_work = df_work.groupby(\"EndOfDayQuote Date\", as_index=False)\n",
        "\n",
        "        # 選択する銘柄数を指定します\n",
        "        number_of_portfolio_stocks = 25\n",
        "\n",
        "        # ポートフォリオの組成方法を戦略に応じて調整します\n",
        "        strategies = {\n",
        "            # リターン・リバーサル戦略\n",
        "            \"reversal\": {\"asc\": True},\n",
        "            # トレンドフォロー戦略\n",
        "            \"trend\": {\"asc\": False},\n",
        "        }\n",
        "\n",
        "        # 戦略に応じたポートフォリオを保存します\n",
        "        df_portfolios = {}\n",
        "\n",
        "        # strategy_id が設定されていない場合は全ての戦略のポートフォリオを作成します\n",
        "        if \"strategy_id\" not in locals():\n",
        "            strategy_id = None\n",
        "\n",
        "        for i in [strategy_id] if strategy_id is not None else strategies.keys():\n",
        "            #  日付毎に戦略に応じた上位25銘柄を選択します。\n",
        "            df_portfolios[i] = grouped_work.apply(\n",
        "                lambda x: x.sort_values(\n",
        "                    \"pct_change\", ascending=strategies[i][\"asc\"]\n",
        "                ).head(number_of_portfolio_stocks)\n",
        "            )\n",
        "\n",
        "        # 銘柄ごとの購入金額を指定\n",
        "        budget = 50000\n",
        "        # 戦略毎に処理\n",
        "        for i in df_portfolios.keys():\n",
        "            # 購入株式数を設定\n",
        "            df_portfolios[i].loc[:, \"budget\"] = budget\n",
        "            # インデックスを日付のみにします\n",
        "            df_portfolios[i].reset_index(level=[0], inplace=True)\n",
        "            # 金曜日から月曜日日付に変更\n",
        "            df_portfolios[i].index = df_portfolios[i].index + pd.Timedelta(\"3D\")\n",
        "\n",
        "        ####\n",
        "        # 出力を調整します\n",
        "        ####\n",
        "        # 戦略毎に処理\n",
        "        for i in df_portfolios.keys():\n",
        "            # インデックス名を設定\n",
        "            df_portfolios[i].index.name = \"date\"\n",
        "            # 出力するカラムを絞り込みます\n",
        "            df_portfolios[i] = df_portfolios[i].loc[:, [\"Local Code\", \"budget\"]]\n",
        "\n",
        "        # 出力保存用\n",
        "        outputs = {}\n",
        "        # 戦略毎に処理\n",
        "        for i in df_portfolios.keys():\n",
        "            # 出力します\n",
        "            out = io.StringIO()\n",
        "            # CSV形式で出力\n",
        "            df_portfolios[i].to_csv(out, header=True)\n",
        "            # 出力を保存\n",
        "            outputs[i] = out.getvalue()\n",
        "\n",
        "        return outputs[strategy_id]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRXXLgllAe8"
      },
      "source": [
        "ファイルが書き込まれていることを確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcVoMzkYlAe8"
      },
      "source": [
        "! ls -l $package_dir/src/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cF86EalAe9"
      },
      "source": [
        "　作成したクラスが適切に動くかを動作確認します。 上記で1行ずつ実行した場合と同一の出力であれば良いことになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC7LJ-bglAe9"
      },
      "source": [
        "# 動作確認します\n",
        "str_ret = ScoringService.predict(inputs, start_dt=pd.Timestamp(\"2020-01-01\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6B_s0R4lAe9"
      },
      "source": [
        "# 出力を確認\n",
        "print(\"\\n\".join(str_ret.split(\"\\n\")[:10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgvzdrBBlAe9"
      },
      "source": [
        "# 出力を保存\n",
        "with open(\"chapter03-tutorial-01-class.csv\", mode=\"w\") as f:\n",
        "    f.write(str_ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVqlT5belAe9"
      },
      "source": [
        "出力が一致していることを確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgiEzpQClAe-"
      },
      "source": [
        "assert outputs[\"reversal\"] == str_ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGyC34-zlAe-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEd8fTJOlAe-"
      },
      "source": [
        "## 10. 提出用パッケージの作成と提出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1AAfXsZlAe_"
      },
      "source": [
        "```\n",
        "3.7.10で作成した `ScoringService` を `predictor.py` に書き込み、Zip形式で圧縮します。今回はシンプルな特徴量を使用してポートフォリオを作成しているため、学習済みのモデルファイルは存在しません。ただし、modelディレクトリは必須であるため、zipファイルには該当のディレクトリを含める必要があります。そのためには、modelファイルには何らかのダミーファイルを作成してzipファイルを作成すると良いでしょう。\n",
        "\n",
        "以下、Zipファイル作成例になります。\n",
        "[source,bash]\n",
        "----\n",
        "$ mkdir model src\n",
        "$ touch model/dummy.txt\n",
        "$ ls\n",
        "model src\n",
        "$ zip -v submit.zip src/predictor.py model/dummy.txt\n",
        "----\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pThKQEyWlAfA"
      },
      "source": [
        "# 提出用パッケージ名\n",
        "package_file = \"chapter03-model.zip\"\n",
        "# パッケージファイルパス\n",
        "package_path = f\"{working_dir}/{package_file}\"\n",
        "\n",
        "# zipファイルを作成\n",
        "with zipfile.ZipFile(package_path, \"w\") as f:\n",
        "    # model/dummy.txtを追加\n",
        "    print(f\"[+] add {package_dir}/model/dummy.txt to model/dummy.txt\")\n",
        "    f.write(f\"{package_dir}/model/dummy.txt\", \"model/dummy.txt\")\n",
        "    # src/predictor.py を追加\n",
        "    print(f\"[+] add {package_dir}/src/predictor.py to src/predictor.py\")\n",
        "    f.write(f\"{package_dir}/src/predictor.py\", \"src/predictor.py\")\n",
        "\n",
        "print(f\"[+] please check {package_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbeZPYqRlAfA"
      },
      "source": [
        "　以上で投稿用のモデルパッケージは完成です。`chapter03-model.zip` ファイルをコンペティションページから投稿してリーダーボードに掲載されることを確認しましょう。\n",
        "\n",
        "　リーダーボードに掲載されたことを確認したら、例えば、特徴量を変更してみたり、複数の特徴量それぞれから10銘柄ずつ選択するロジックを実装してみるのはどうでしょうか。いくつかの特徴量については「<<anchor-2.7,2.7. 特徴量の生成>>」で説明していますのでご参照ください。特に、「2.7.2. 定常性を意識した特徴量設計」は重要な概念ですのでご一読ください。\n",
        "\n",
        "次章では、2章で作成した機械学習モデルを使用してポートフォリオを組成する方法について記載しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDNjoihSlAfA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
